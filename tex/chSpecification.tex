\Chapter{Boolean Reflection}{}
\label{ch:boolrefl}

% in addition to the photos:
% \begin{itemize}
% \item talk about /= in 2 as a decorator for elim on a list (since arithmetics is all locked with nosimpl).
% \item talk about nosimpl in 3.3, say that according to our experience simpl is not
% always a good idea hence nosimpl.
% \item good practice (3.3 or 3.4): state and prove the fixpoint unfolding/folding equations.
% \end{itemize}



%\section{Motivations}

At this stage, we are in the presence of one of the main issues in the
representation of mathematics in a formal language: Very often,
several datastructures can be used to represent one and the same
mathematical definition or statement. The choice between them
may have a significant impact
on the upcoming layers of formalized theories. So far, we have seen two
ways of expressing logical statements: using boolean predicates and
truth values on one hand, and using logical connectives and the
\C{Prop} sort on the other. For instance, in order to define the
predicate ``the sequence \C{s} has at least one element satisfying the
(boolean) predicate \C{a}'', we can either use a boolean predicate:

\begin{coq}{}{}
Fixpoint has T (a : T -> bool) (s : seq T) : bool :=
  if s is x :: s' then a x || has a s' else false.
\end{coq}

or we can use an alternate formula, like for instance:

\begin{coq}{}{}
Definition has_prop  T (a : T -> bool) (x0 : T) (s : seq T) :=
   exists i, i < size s /\ a (nth x0 s i)
\end{coq}

(where we are assuming that \C{x0} is a given element of \C{T};
otherwise, we can, e.g., quantify the whole statement by
\C{exists (x0 : T)}).

Term \C{(has a s)} is a boolean value.  It is hence
easy to use it in a proof to perform a case
analysis on the fact that sequence
\C{s} has an element such that \C{a} holds, using the \C{case} tactic:

\begin{coq}{}{}
case: (has a s).
\end{coq}
As we already noted, computation provides some automation for free.
For example
in order to establish that \C{(has odd [:: 3; 2; 7]) =
  true}, we only need to observe that the left hand side \emph{computes} to
\C{true}.

It is not possible to perform a similar case analysis in a proof
using the alternative version \C{(s_has_aP : has_prop a x0 s)},
since, as sketched in section~\ref{sec:EM}, excluded middle holds in
\Coq{} only for boolean tests.
On the
other hand, this phrasing of the hypothesis easily gives access to the
value of the index at which the witness is to be found:

\begin{coq}{}{}
case: s_has_aP => [n [n_in_s asn]].
\end{coq}
introduces in the context of the goal a natural number \C{n : nat} and
the fact \C{(asn : a (nth x0 s n))}. In order to establish that
\C{(has_prop a x0 s)}, we cannot resort to computation. Instead, we can
prove it by providing the index at which a witness is
to be found  --- plus a proof of this fact --- which may be better suited
for instance to an abstract sequence \C{s}.

In summary, boolean statements are especially convenient for excluded
middle arguments and its variants (reductio ad
absurdum, \ldots). They furthermore provide a form of small-step
automation by computation.\footnote{They moreover allow for
  proof-irrelevant specifications. This feature is largely used
  throughout the Mathematical Components library but beyond the scope
  of the present chapter: it will be the topic of
  chapter~\ref{ch:sigmabool}.}
Specifications in the \C{Prop} sort
are structured logical statements, that can be ``destructed'' to
provide witnesses (of existential statements), instances (of universal
statements), subformulae (of conjunctions), etc.. They are proved by
deduction, building proof trees made with the rules of the
logic. Formalizing a predicate by means of a boolean specification
requires implementing a form of decision
procedure and possibly proving a specification lemma if
the code of the procedure is not a self-explanatory description of the
%standard axiomatic description of the
mathematical notion. For instance a
boolean definition \C{(prime : nat -> bool)} implements a complete
primality test, which requires a companion lemma proving that it is
equivalent to the usual definition in terms of proper
divisors. Postulating the existence of such a decision procedure for a
given specification is akin to assuming that the excluded middle
principle holds on the corresponding predicate.

The boolean reflection methodology proposes to avoid
committing to one or the other of these options, and provides enough
infrastructure to ease the bureaucracy of navigating between the two.
The \C{is_true} coercion, which was being used silently in the
background since the early pages of chapter~\ref{ch:proofs}, is in
fact one piece of this infrastructure.

\begin{coq}{}{title=The is\_true coercion}
Definition is_true (b : bool) : Prop := b = true.
Coercion is_true : bool >-> Sortclass.
\end{coq}
The \C{is_true} function is automatically inserted by \Coq{} to
turn a boolean value into a \C{Prop}, i.e. into a regular statement
of a theorem.
More on this mechanism will be told in section~\ref{sec:coercions}.

% It is worth recalli body of the \C{is_true} function is just an equality, and hence
% can be used to replace the boolean expression by its truth value with the
% \C{rewrite} tactic.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Reflection views}\label{sec:views}
\index[concept]{reflection view}

\subsection{Relating statements in \C{bool} and \C{Prop}}\label{ssec:boolProp}

How to best formalize the equivalence between a boolean value \C{b}
and a statement \C{P : Prop}? The most direct way would be to use the
conjunction of the two converse implications:

\begin{coq}{}{}
Definition bool_Prop_equiv (P : Prop) (b : bool) := b = true <-> P.
\end{coq}
where \C{(A <-> B)} is defined as \C{((A -> B) /\\ (B -> A))}.

Yet, as we shall see in this section, we can improve the phrasing of
this logical sentence, in order to improve its usability. For
instance, although \C{(bool_Prop_equiv P b)} implies that the excluded
middle holds for \C{P}, it does not provide directly a convenient way
to reason by case analysis on the fact that \C{P} holds or not, or to
use its companion version \C{(b = false <-> ~ P)}. The following proof
script illustrates the kind of undesirable bureaucracy entailed by
this wording:

\begin{coq}{}{width=7cm}
Lemma test_bool_Prop_equiv b P : bool_Prop_equiv P b -> P \/ ~ P.
Proof.
case: b; case => hlr hrl.
  by left; apply: hlr.
by right => hP; move: (hrl hP).
Qed.
\end{coq}
\begin{coqout}{}{width=5cm,title=Last goal}
1 subgoal
P : Prop
hlr : false = true -> P
hrl : P -> false = true
========================
P \/ ~ P
\end{coqout}
We could try
alternative formulations based on the connectives seen in
section~\ref{ch:ttch}, like for instance
\C{(b = true /\\ P) \\/ (b = false /\\ ~ P)}, but again the bureaucracy
would be non-negligible.

A better solution is
to use an ad-hoc inductive definition that resembles a
disjunction of conjunctions: we inline the two constructors of a
disjunction and each of these constructors has the two arguments of
the conjunction's single constructor:

\begin{coq}{}{label=lst:reflect1}
Inductive reflect (P : Prop) (b : bool) : Prop :=
| ReflectT (p : P)    (e : b = true)
| ReflectF (np : ~ P) (e : b = false).
\end{coq}
\index[coq]{\C{reflect}}

We can prove that the statement \C{reflect P b} is actually equivalent
to the double implication \C{bool_Prop_equiv}; see exercise~\ref{ex:iffp}.

Let us illustrate the benefits of this alternate specialized double
implication:

\begin{coq}{}{width=6cm}
Lemma test_reflect b P :
  reflect P b -> P \/ ~ P.
Proof.
case.
\end{coq}
\begin{coqout}{}{width=6cm}
  b : bool
  P : Prop
  ============================
   P -> b = true -> P \/ ~ P

subgoal 2 is:
 ~ P -> b = false -> P \/ ~ P
\end{coqout}

A simple case analysis on the hypothesis \C{(reflect P b)} exposes in
each branch both versions of the statement.
%: one in its \C{Prop}
%version, and the corresponding boolean equation.
Note that the actual
\C{reflect} predicate defined in the \C{ssrbool} library is
slightly different from the one we give here:
%Listing~\ref{lst:reflect1}:
this version misses an ultimate refinement
%\footnote{Moreover the \C{reflect}
%predicate is in fact in sort \C{Type}, which will hopefully make sense
%when reading chapter~\ref{ch:sigmabool}},
that will be presented in
section~\ref{ssec:specs}.
%Until then, we
%we reach section~\ref{ssec:specs}, we
%act as if Listing~\ref{lst:reflect1} is the official definition
%of \C{reflect}.

%\marginnote{Do not really know how to make this clearer... Plus the
%  LaTeX counter for listings could be improved.}

We start our collection of links between boolean and \C{Prop}
statements with the lemmas relating boolean connectives with their
\C{Prop} versions:

\begin{coq}{}{}
Lemma andP (b1 b2 : bool) : reflect (b1 /\ b2) (b1 && b2).
Proof.  by case: b1; case: b2; [ left | right => //= [[l r]] ..]. Qed.

Lemma orP (b1 b2 : bool) : reflect (b1 \/ b2) (b1 || b2).
Proof.
case: b1; case: b2; [ left; by [ move | left | right ] .. |].
by right=> // [[l|r]].
Qed.

Lemma implyP (b1 b2 : bool) : reflect (b1 -> b2) (b1 ==> b2).
Proof.
by case: b1; case: b2; [ left | right | left ..] => //= /(_ isT).
Qed.
\end{coq}
\index[coq]{\C{andP}}
\index[coq]{\C{orP}}
\index[coq]{\C{implyP}}

In each case, the lemma is proved using a simple inspection by
case analysis of the truth table of the boolean formula. The case
analysis generates several branches and we use a special syntax to
describe the tactics which should be applied to some specific
branches, and the tactic which should be applied in the general case.
The ``\C{;[ t1 | t2 .. | tn ]}'' syntax indeed corresponds to the
application of the tactic \C{t1} to the first subgoal generated by
what comes before \C{;}, and the application of the tactic \C{tn} to the
last subgoal, and the application of the tactic \C{t2} to all the
branches in between. See~\cite[section 9.2]{Coq:manual}) for a
complete description of this feature.
\index[ssr]{\C{;[..|..]}}

More generally, a theorem stating an equivalence between a boolean
expression and a \C{Prop} statement is called a
\emph{reflection view}, since it is used to view an assumption from a
different perspective.

\mantra{The name of a reflection view always ends with a capital \C{P}.}

The next section is devoted to the proof and usage of more involved views.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Proving reflection views}

Reflection views are also used to specify types equipped with a
\emph{decidable equality}, by showing that the equality predicate
\C{eq} (seen in section~\ref{ssec:indtypes}) is implemented by a
certain boolean equality test. For instance, we can specify the
boolean equality test on type \C{nat} implemented in
chapter~\ref{ch:prog} as:

\begin{coq}{}{}
Lemma eqnP (n m : nat) : reflect (n = m) (eqn n m).
\end{coq}
\index[coq]{\C{eqnP}}

%\marginnote{In fact, \C{eqnP} is stated using Equality.axiom}
Each implication can be proved by a simple induction on one of the
natural numbers, but we still need to generate the two subgoals
corresponding to these implications, as the \C{split} tactic is of no
help here.

%\marginnote{Proving these implications would be a good exercise in the
%  previous chapter. Solution described below in (comments in) the sources.}

% Indeed if \C{n = m} holds, then we can prove that
% \C{eqn n m = true} by first substituting \C{m} by \C{n} and then
% proving that \C{eqn n n = true} by induction on \C{n}. Now if
% \C{eqn n m = true}, we will show that \C{n = m} holds by
% reasoning by induction on \C{n} and by case analysis on \C{m}. The
% base case is easy: if \C{n} is \C{O} and \C{m} is not, the \C{eqn n m}
% evaluates to \C{false} and the hypothesis \C{eqn n m = true} is thus
% convertible to \C{false = true}, which allows reductio ad absurdum. In
% the recursive case, we know that \C{forall m, eqn n m = true -> n = m}
% and we want to prove that
% \C{forall m, eqn n.+1 m = true -> n.+1 = m}. Again, we perform a case
% analysis on \C{m} and the case when \C{m} is zero is easy. Now if
% \C{m} is of the form \C{k.+1}, we need to prove that
% \C{eqn n.+1 k.+1 =true -> n.+1 = k.+1}, or equivalently (by
% conversion) that
% \C{eqn n k =true -> n.+1 = k.+1}. The premise of this implication can
% feed our induction hypothesis and we thus know that \C{n = k}, which
% is sufficient to prove that \C{n.+1 = k.+1} by substitution.

In order to trigger this branching in the proof tree, we resort to the
bridge between the \C{reflect} predicate and a double implication.
The \C{ssrbool} library provides a general version of
this bridge:
% than the one we proved in exercise~\ref{}
% section~\ref{ssec:boolProp}:

\begin{coq}{}{width=3cm}
About iffP.
\end{coq}
\begin{coqout}{}{width=9cm}
iffP : forall (P Q : Prop) (b : bool),
  reflect P b -> (P -> Q) -> (Q -> P) -> reflect Q b
\end{coqout}
\index[coq]{\C{iffP}}
Lemma \C{iffP} relates two equivalences \C{(reflect P b)}
and \C{(reflect Q b)} involving one and the same boolean \C{b}
but different \C{Prop} statements \C{P} and \C{Q}, as soon as one
provides a proof of the usual double implication between \C{P} and
\C{Q}.
%\marginnote{Prove it as an exercise?}
% Statement \C{(@iffP_lr P b)} in the exercise can be obtained as the
% specialization \C{(@iffP _ _ (@idP b))} where \C{idP} is the
% trivial reflexive\footnote{Note that the first occurrence of \C{b} is
% coerced to \C{Prop} by \C{is\_true}} equivalence:

The trivial reflection view is called \C{idP} and is seldom used
in conjunction with \C{iffP}.

\begin{coq}{}{}
Lemma idP {b : bool} : reflect b b.
\end{coq}
\index[coq]{\C{idP}}
% \marginnote{The tuning of implicits is crucial for the \C{apply: (iffP idP)} to behave correctly.}
We can now come back to the proof of lemma \C{eqnP}, and start its
proof script by applying \C{iffP}.

\begin{coq}{}{width=7cm}
Lemma eqnP {n m : nat} :
  reflect (n = m) (eqn n m).
Proof.
apply: (iffP idP).
\end{coq}
\begin{coqout}{}{width=5cm}
n : nat
m : nat
===================
 m = n -> eqn m n

subgoal 2 is:
 eqn m n -> m = n
\end{coqout}
The proof is now an easy induction, and is left as exercise~\ref{ex:eqnP}.

% In fact the library does not feature the specialization \C{iffP_lr},
% and the idiom to remember in order to prove a reflection lemma by
% double implication is the \C{apply: (iffP idP)} command.
Let us now
showcase the usage of the more general form of \C{iffP} by proving
that a type equipped with an injection in type \C{nat} has a
decidable equality:

\begin{coq}{}{}
Lemma nat_inj_eq T (f : T -> nat) x y :
  injective f -> reflect (x = y) (eqn (f x) (f y)).
\end{coq}
The equality decision procedure just consists in pre-applying
the injection \C{f} to the decision procedure \C{eqn} available on
type \C{nat}. Since we already know that \C{eqn} is a decision
procedure for equality, we just need to prove that \C{(x = y)} if and
only if \C{(f x = f y)}, which  follows directly from the injectivity of
\C{f}. Using \C{iffP}, a single proof command splits the goal into two
implications, replacing on the fly the evaluation
\C{(eqn (f x) (f y))} by the \C{Prop} equality \C{(f x = f y)}:

\begin{coq}{}{width=7.7cm}
Lemma nat_inj_eq T (f : T -> nat) x y :
  injective f ->
    reflect (x = y) (eqn (f x) (f y)).
Proof.
move=> f_inj.
apply: (iffP eqnP).
\end{coq}
\begin{coqout}{}{width=4.3cm}
T : Type
f : T -> nat
f_inj : injective f
x, y : T
====================
x = y -> f x = f y

subgoal 2 is:
 f x = f y -> x = y
\end{coqout}
Note that \C{eqn}, being completely specified by \C{eqnP}, is not
anymore part of the picture.  Finishing the proof is left as
exercise~\ref{ex:eqnPinj}.

The latter example illustrates the convenience of combining an action
on a goal, here breaking an equivalence into one subgoal per
implication, with a change of viewpoint, here by the means of the
\C{eqnP} view. This combination of atomic proof steps is pervasive in
a library designed using the boolean reflection methodology: the
Ssreflect tactic language lets one use view lemmas freely
in the middle of intro-patterns.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Using views in intro patterns}

Reflection views are typically used in the bookkeeping parts of formal
proofs, and thus often appear as views in intro patterns, as described
in section~\ref{ssec:stack}. Actually, view intro patterns are named
after reflection views because this feature of the tactic language was
originally designed for what is now the special case of reflection
views. For instance, suppose
that one wants to access the components of a conjunctive hypothesis,
stated as a boolean conjunction. We can use lemma \C{andP} in a view
intro-pattern in this way:

\begin{coq}{}{width=6cm}
Lemma example n m k : k <= n ->
  (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP.
\end{coq}
\begin{coqout}{}{width=6cm}
n, m, k : nat
lekn : k <= n
==========================
 n <= m /\ m <= k -> n = k
\end{coqout}

The view intro-pattern \C{/andP} has \emph{applied} the reflection
view \C{andP} to
the top entry of the stack \C{(n <= m) && (m <= k)} and transformed it into
its equivalent form \C{(n <= m) /\\ (m <= k)}. Note that strictly
speaking, lemma \C{andP} does not have the shape of an implication,
which can be fed with a proof of its premise: it is (isomorphic to) the
conjunction of \emph{two} such implications. The \emph{view mechanism}
implemented in the tactic language has automatically guessed and
inserted a term, called \emph{hint view}, which plays the role of an
adaptor.
\index[vernac]{\C{Hint View}}

More precisely the \C{/andP} intro pattern has wrapped the top
stack item, called \C{top} here, of type \C{((n <= m) && (m <= k))} into
\C{(elimTF andP top)} obtaining a term of type
\C{((n <= m) /\\ (m <= k))}.

\begin{coq}{}{}
Lemma elimTF (P Q : Prop) (b c : bool) :
  reflect P b -> b = c -> if c then P else ~ P.
\end{coq}
\index[coq]{\C{elimTF}}
Term \C{(elimTF andP top)} hence has type

\begin{coq}{}{}
if true then (n <= m) /\ (m <= k) else ~ ((n <= m) /\ (m <= k))
\end{coq}
which reduces to \C{((n <= m) /\\ (m <= k))} since \C{c} is \C{true}
(recall the hidden ``\C{.. = true}'' in the type of the top stack entry).
%\marginnote{Show other examples of inserted hint views? Like negation...}

Going back to  our example: we can then chain this view with a case
intro-pattern to break the conjunction and introduce its components:

\begin{coq}{}{width=6cm}
Lemma example n m k : k <= n ->
  (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP[lenm lemk].
\end{coq}
\begin{coqout}{}{width=6cm}
n, m, k : nat
lekn : k <= n
lenm : n <= m
lemk : m <= k
===========================
n = k
\end{coqout}

As \C{(n <= m)} is by definition \C{(n - m == 0)}, we can use the
reflection view
\C{eqnP} in order to transform this hypothesis into a proper equation.
Observe the new shape of the \C{lenm} hypothesis:

\begin{coq}{}{width=7cm}
Lemma example n m k : k <= n ->
  (n <= m) && (m <= k) -> n = k.
Proof.
move=> lekn /andP [/eqnP lenm lemk].
\end{coq}
\begin{coqout}{}{width=5.1cm}
n, m, k : nat
lekn : k <= n
lenm : n - m = 0
lemk : m <= k
===========================
n = k
\end{coqout}

\mantra{
Combining wisely the structured reasoning of inductive predicates
in \C{Prop} with the ease to reason by equivalence via rewriting
of boolean identities leads to concise proofs.
}

Let us now move to a non-artificial example to see how the Ssreflect
tactic language supports the combination of views with the \C{apply},
\C{case} and \C{rewrite} tactics.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Using views with tactics}\label{sec:viewtac}

We dissect the proof that \C{<=} is a total relation.
As usual the statement is expressed as a boolean formula:

\begin{coq}{}{}
Lemma leq_total m n : (m <= n) || (m >= n).
\end{coq}

The first step of the proof is to view this disjunction as an
implication, using the classical equivalence and a negated premise:

\begin{coq}{}{width=7.6cm}
Lemma leq_total m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb.
\end{coq}
\begin{coqout}{}{width=4.7cm}
m, n : nat
=====================
~~ (m <= n) ==> (n <= m)
\end{coqout}

This premise can be seen as \C{n < m}:

\begin{coq}{}{width=7.6cm}
Lemma leq_total m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb -ltnNge.
\end{coq}
\begin{coqout}{}{width=4.5cm}
m, n : nat
=====================
(n < m) ==> (n <= m)
\end{coqout}

This is now an instance of the weakening property of the comparison,
except that it is expressed with a boolean implication. But the view
mechanism not only exists in intro-patterns: it can also be used in
combination with the \C{apply} tactic, to apply a view to a given goal
with a minimal amount of bureaucracy:

\begin{coq}{}{width=7.6cm}
Lemma leq_total m n : (m <= n) || (m >= n).
Proof.
rewrite -implyNb -ltnNge; apply/implyP.
\end{coq}
\begin{coqout}{}{width=4.5cm}
m, n : nat
=====================
(n < m) -> (n <= m)
\end{coqout}

We can now conclude the proof:

\begin{coq}{}{}
Lemma leq_total m n : (m <= n) || (m >= n).
Proof. by rewrite -implyNb -ltnNge; apply/implyP; apply: ltnW. Qed.
\end{coq}
\\

The \C{case} tactic also combines well with the view mechanism, which
eases reasoning by cases along a disjunction expressed with a boolean
statement, like the just proved \C{leq_total}.  For example we
may want to start the proof of the following lemma by distinguishing
two cases: \C{n1 <= n2} and \C{n2 <= n1}.

\begin{coq}{}{}
Lemma leq_max m n1 n2 :
  (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
case/orP: (leq_total n2 n1) => [le_n21 | le_n12].
\end{coq}
That results in:

\begin{coqout}{}{}
m, n1, n2 : nat
le_n21 : n2 <= n1
============================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal two is:
 (m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}
Even if it is not displayed here, subgoal two has \C{(n1 <= n2)}
in its context.

Finally, the \C{rewrite} tactic also handles views that relate an
equation in \C{Prop} with a boolean formula.

\begin{coq}{}{}
Lemma maxn_idPl {m n} : reflect (maxn m n = m) (m >= n).

Lemma leq_max m n1 n2 :
  (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
case/orP: (leq_total n2 n1) => [le_n21 | le_n12].
  rewrite (maxn_idPl le_n21).
\end{coq}
The tactic sees \C{(maxn_idPl le_n21)} as the equation corresponding
to the boolean formula \C{le_n21}, namely \C{(maxn n1 n2 = n1)},
and rewrites with it obtaining:

\begin{coqout}{}{}

  m : nat
  n1 : nat
  n2 : nat
  le_n21 : n2 <= n1
  ============================
   (m <= n1) = (m <= n1) || (m <= n2)

subgoal 2 is:
 (m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

The full proof of \C{leq_max} is quite interesting and will be
detailed in section~\ref{sec:leqmax}

% \marginnote{We could propose another exercise in next section in order
% to factor this proof with a \C{wlog}.}
% \begin{itemize}

% \item Example of \C{eqnP}, that is \C{eqP} specialized to
%   \C{nat}. Proof using \C{(iffP idP)}. Explain \C{iffP} and \C{idP} is
%   the dummay case.

% \item Another example: Simplified instance of \C{inj_eqAxiom} in
%   section  \C{TransferEqType} of \C{eqtype.v}, with \C{nat} as
%   codomain. Proof with \C{(iffP eqnP)}.

% \item Using views, with tactics. First, example of using \C{eqnP} in
%   an intro pattern, like \C{=> /eqnP ->}. Note that the direction in
%   which the view should be used has been guessed
%   automatically. Explain which adapter has been inserted (as a hint).

% \item Then show the cute proof of \C{leq_total}, which features
%   \C{apply/implyP}.

% \item Finally, show \C{case/orP: (leq_total n m)}. May be a first
%   simple and dummy example. Then one possibility is
%   to show a simplified version of the proof of \C{leq_max}, removing
%   the \C{without loss}. This features \C{case/orP: (leq_total n2 n1)}
%   and \C{rewrite (maxn_idPl le_n21)} which uses the \C{elimT} coercion.
%   This could be reused in the next section, to illustrate \C{wlog}.
%
%
% \item There are more adaptors than \C{introT, introF, elimT, elimF},
%   in particular with negations \C{elimN,...} and \C{apply/v1/v2}.

% \end{itemize}

% Note that the view feature in the tactic language is there to combine an
% action (tactic or intro pattern) with a change of world. Order in
% which we could introduce it: \C{/eqP ->}, \C{/andP [h1 h2]},
% \C{/orP [h1 | h2]}. May be mention \C{=> /v1 /v2} as a side remark.

% It is the fragment of decidable stuff (EM as case).
% It is a concrete data type on which you can program (SSR), automation by
% computation.

% % \begin{coq}{name=Ex}{}
% % Lemma muln_eq0 m n :
% %   ((m * n = 0) -> (m = 0) \/ (n = 0)) /\
% %   ((m = 0) \/ (n = 0) -> (m * n = 0))
% % Proof.
% % Qed.
% %
% % Lemma leq_mul2l m n1 n2 :
% %   (m * n1 <= m * n2) = (m == 0) || (n1 <= n2).
% % Proof.
% % Qed.
% % \end{coq}



% \begin{coq}{name=Ex}{}
% Lemma leq0n n : (0 <= n) (* = true *).
% \end{coq}

% NOt everything can be in bool, e.g. exists or a real reasoning by cases
% on a disjunction. Inductives give you the tree structure in natural
% deduction, not bools.

% \begin{coq}{name=Ex}{}
% Lemma ...
% case/orbP : (leq_total n m)
% \end{coq}

% We need lemmas to relate

% \begin{coq}{name=Meaning of reflect}{}
% Definition reflect P b : Prop :=  b -> P /\ P -> b

% Lemma orbP p q : reflect (p \/ q) (p || q).
% \end{coq}

% so frequent and so many variations that we have proper infrastructure like
% being able to invoke views everywhere and have 1 view per connective (negate or
% not...).

% \begin{coq}{}{}
% Lemma introT  : P -> b.            Proof using Pb. exact: introTF true _. Qed.
% Lemma introF  : ~ P -> b = false.  Proof using Pb. exact: introTF false _. Qed.
% Lemma introN  : ~ P -> ~~ b.       Proof using Pb. exact: introNTF true _. Qed.
% Lemma introNf : P -> ~~ b = false. Proof using Pb. exact: introNTF false _. Qed.
% Lemma introTn : ~ P -> b'.         Proof using Pb'. exact: introTFn true _. Qed.
% Lemma introFn : P -> b' = false.   Proof using Pb'. exact: introTFn false _. Qed.
% \end{coq}

% \section{how to use reflect lemmas as tactic decorators}

% we make examples with andP orP negP in move/P, apply/P, case/P.

% we explain the hint view, plus the extra impl arguments.

% some view can be partial, A -> B -> reflect B c.

% \subsection{The view mechanism in intro pattern}

%   a == b \&\& bb

% views applied to top, inline destructuring and subst:
%   => /andP[/eqP-> pb] ->.

% Fwd and backward declarative steps.
% have : P x := ... H ...
% suff.

% Handling symmetries:
% gen have: x Hx / P x.

% managing large goals and contexts: set, -/x /x

% help the reader with typographical comments, like leaving an empty
% line in latex (here we use bullets).

\section{Advanced, practical, statements}

As we have already hinted previously, the shape of a lemma is very important.
There are many ways to express the same concept, but, unsurprisingly,
one can be easier to access than the others.  In particular there are classes of
lemmas that \emph{specify} a concept, and as a consequence shape the proofs
involving such notion.

% TODO: Not everything needs to be a tactic, the logic is powerful
% enough to express special connectives that induce a line of
% reasoning. Hence this section.
% General talk about the fact that statements/definition do matter: not only for
% their meaning but also because they have implications on the
% usability/practicality in the rest of the library.  At least two classes of
% techniques, the ones based on the logic (bool refl, reflect, classically, order
% of forall when instantiation done via CH) and the ones based on the support of
% the prover (implicit args, type inference CS, Hint Resolve).
% More in general, this has to be mentioned in the main intro of the book, here
% we revise the idea.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inductive specs with indices}\label{ssec:specs}
What we did for \C{reflect}, an ad hoc connective, to model a line of reasoning, is
a recurrent pattern in the \mcbMC{} library.  Such class of inductive
predicates is called ``spec'', for \emph{specification}.

Spec predicates are inductive families with indexes, exactly
as the \C{eq} predicate seen in section~\ref{ssec:indtypes}.
In particular their elimination rule encapsulates the notion
of substitution, and that operation is performed automatically by
the logic.

If we look at \C{reflect}, and its use, one is very likely to substitute \C{b}
for its value in each branch of the case.

\begin{coq}{}{}
Inductive reflect (P : Prop) (b : bool) : Prop :=
| ReflectT (p : P)    (e : b = true)
| ReflectF (np : ~ P) (e : b = false)
\end{coq}

This alternative formulation makes the equation implicitly stated and
also automatically substituted during case analysis.

\begin{coq}{}{}
Inductive reflect (P : Prop) : bool -> Prop :=
| ReflectT (p : P)    : reflect P true
| ReflectF (np : ~ P) : reflect P false
\end{coq}
\index[coq]{\C{reflect}}

Here the second argument of \C{reflect} is said to be an \emph{index}
and it is allowed to vary depending on the constructor: \C{ReflectT} always
builds a term of type \C{(reflect P true)} while \C{ReflectF} builds
a term of type \C{(reflect P false)}.  When one reasons
by cases on a term of type \C{(reflect P b)} he obtains two proof
branches, in the first one \C{b} is replaced by \C{true}, since it
corresponds to the \C{ReflectT} constructor.  Conversely,
\C{b} is replaced by \C{false} in the second branch.

Let's take an example where we reason by cases on the \C{andP} lemma,
that states \C{(forall a b, reflect (a /\\ b) (a && b))}.

\begin{coq}{}{width=6cm}
Lemma example a b :
  a && b ==> (a == b).
Proof.
case: andP => [ab|nab].
\end{coq}
\begin{coqout}{}{width=6cm}
a, b : bool
ab : a /\ b
========================
true ==> (a == b)

subgoal 2 is:
false ==> (a == b)
\end{coqout}

Remark how the automatic substitution trivializes the
second goal.  The first one can be solved by replacing
both \C{a} and \C{b} by their truth values, once \C{ab}
is destructed.  Hence the full proof script is:

\begin{coq}{}{}
Lemma example a b : a && b ==> (a == b).
Proof. by case: andP => [[-> ->] |]. Qed.
\end{coq}

Note that we have not specified a value for the
variables quantified in the statement of \C{andP}.
Such a view is in fact accompanied by an implicit argument declaration
as follows:

\begin{coq}{}{}
Arguments andP {a b}.
\end{coq}
\index[vernac]{\C{Arguments}}
We recall that this makes \C{a} and \C{b} implicit, hence
writing \C{andP} is equivalent to \C{(@andP _ _)} whose type
is \C{(reflect (_ /\\ _) (_ && _))}.  The value of the index of the
inductive family to be replaced by \C{true} or \C{false} is here
a pattern \C{(_ && _)} and the goal is searched for an instance of
such pattern by the same matching algorithm the \C{rewrite} tactic
uses for rewrite rules.
Tuning of implicit arguments is key to obtaining easy to use
lemmas, even more the ``spec'' ones.


If one needs to override the pattern inferred for the index
of \C{andP}, he can provide one by hand as follows:

\begin{coq}{}{}
Lemma example a b : (a || ~ a) && (a && b ==> (a == b)).
Proof. by case: (a && _) / andP => [[-> ->] |] //; rewrite orbN. Qed.
\end{coq}
A more detailed explanation of this syntax can be found
in~\cite[section 5.6]{ssrman}.

The \mcbMC{} library provides many spec lemmas to be used this way.
A paradigmatic one is \C{ifP}.

\begin{coq}{}{}
Section If.
Variables (A : Type) (vT vF : A) (b : bool).

Inductive if_spec : bool -> A -> Type :=
| IfSpecTrue  (p : b)         : if_spec true vT
| IfSpecFalse (p : b = false) : if_spec false vF.

Lemma ifP : if_spec b (if b then vT else vF).
\end{coq}
\index[coq]{\C{ifP}}

Reasoning by cases on \C{ifP} has the following effects:
1) the goal is searched for an expression like \C{(if _ then _ else _)};
2) two goals are generated, one in which the condition of the if
statement is replaced by \C{true} and the if-then-else expression
by the value
of the then branch, another one where  the condition is replaced by
\C{false} and the if-then-else by the value of the else branch;
3) the first goal gets an extra assumption \C{(b = true)}, while
the second goal gets \C{(b = false)}.
Note that ``\C{case: ifP}'' is very compact, much shorter than any if-then-else
expression.

It is worth mentioning the convenience lemma \C{boolP} that takes a boolean
formula and reasons by excluded middle providing some extra comfort
like an additional hypothesis in each sub goal.

Another reflection view worth mentioning is \C{leqP} that replaces, in one shot,
both \C{(_ <= _)} and the converse \C{(_ < _)} by opposite truth values.
Sometime a proof works best by splitting into three branches, i.e.,
separating the equality case. The \C{ltngtP} lemma is designed for that.
\index[coq]{\C{leqP}}
\index[coq]{\C{ltngtP}}

In practice lines of reasoning consisting in a specific branching of
a proof can often be modelled by an appropriate spec lemma.

\mantra{The structure of the proof shall not be driven by the syntax of the
definition/predicate under study but by the view/spec used to reason about it}

% \subsection{TBD: dependent elimination (**)}

% explain return match clause.  Maybe just the syntax we provide here and
% there, the / annotation for elim/case, and then point to other texts explaining
% the thing.  \mcbMC{} does not use such thing but for spec.

% \subsection{Other tools to craft good statements}

% \begin{itemize}
% \item Use macros (\C{left_commutative} or notations like
% \C{\{in A, bijective f\}}, and3, ...)
% \item Use naming conventions
% \item Classically (do not insist too much)
% \item iff (\C{AGM}): find examples?
% \item Tuning of implicit arguments
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\section{Real proofs, finally!}\label{sec:realproofs}

So far we've only tackled simple lemmas; most of them did admit a one line
proof.  When proofs get longer \emph{structure} is the best ally in making
them readable and maintainable.  Structuring proofs means identifying
intermediate results, factor similar lines of reasoning (e.g., symmetries),
signal crucial steps to the reader, and so on.  In short, a
proof written in \Coq{} should not look too different from a proof
written on paper.

The first subsection introduces the \C{have} tactic, that is the key
to structure proofs into intermediate steps.  The second subsection
deals with the ``problem'' of symmetries.  The third one uses most
of the techniques and tactics seen so far to prove correct the
Euclidean division algorithm.  The three subsections contain
material in increasing order of difficulty.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbsubsection{Primes, a never ending story}\label{sec:infprimes}
\index[concept]{forward reasoning}

Saying that primes are infinite can be phrased as: for any natural number
$m$, there exists a prime greater than $m$.  The proof of this claim goes like
that: every natural number greater than 1 has at least one prime divisor.  If
we take $m! + 1$, then such prime divisor $p$ can be shown to be greater than $m$ as
follows.  By contraposition we assume $p \leq m$ and we show that $p$
does not divide $m!+1$.
Being smaller than $m$, $p$ divides $m!$, hence to divide $m!+1$, $p$ should divide
$1$; that is not possible since $p$ is prime, hence greater than 1.
\hfill$\square$

We first show that any positive number smaller than $n$ divides $n!$.

\begin{coq}{}{}
Lemma dvdn_fact m n : 0 < m <= n -> m %| n`!.
Proof.
case: m => //= m; elim: n => //= n IHn; rewrite ltnS leq_eqVlt.
by case/orP=> [/eqP-> | /IHn]; [apply: dvdn_mulr | apply: dvdn_mull].
Qed.
\end{coq}

After the first line the proof state is the following one:

\begin{coqout}{}{}
m, n : nat
IHn : m < n -> m.+1 %| n`!
========================
(m == n) || (m < n) -> m.+1 %| (n.+1)`!
\end{coqout}
The case analysis rules out \C{(m = 0)}, and simplifies the hypothesis
to \C{(m <= n)}.  Recall that \C{(x <= y <= z)} is a notation for \C{((x <= y) &&
(y <= z))}; hence when the first inequality evaluates to true (e.g. when \C{x}
is 0) the conjunction simplifies to the second conjunct.  The \C{leq_eqVlt}
rewrite rule rephrases \C{<=} as a disjunction (the capital \C{V} letter
is reminiscent of $\lor$).

When we reason by cases on the top assumption, line 4, we face two goals, both
easy to solve if we look at the development of the factorial of \C{n.+1},
i.e., \D{(n.+1 * n`!)}.  The former amounts to showing that
\D{(n.+1 \%| n.+1 * n`!)}, while the latter to showing that \D{(m.+1 \%| n.+1 *
n`!)} under the (inductive) hypothesis that \D{(m.+1 \%| n`!)}.

What is paradigmatic in this little proof is the use of the \emph{goal stack
as a work space}.  In other words the proof script would be much more involved
if we started by introducing in the proof context all assumptions.
\\

We can now move to the proof of the main result.  We state it using a
``synonym'' of the exists quantifier that is specialized to carry two
properties.  This way the statement is simpler to destruct: with just one
case analysis we obtain the witness and the two properties.
We also resort to the following lemmas.

\begin{coq}{}{title=Tools}
Lemma fact_gt0 n : 0 < n`!.
Lemma pdivP n : 1 < n -> exists2 p, prime p & p %| n,
Lemma dvdn_addr m d n : d %| m -> (d %| m + n) = (d %| n).
Lemma gtnNdvd n d : 0 < n -> n < d -> (d %| n) = false.
\end{coq}
The first step is to prove that $m! + 1$ is greater than $1$, a triviality.
Still it gives us the occasion to explain the \C{have} tactic, which lets us
augment the proof context with a new fact, typically an intermediate step of
our proof.
\index[ssr]{\C{have name : type}}
\index[ssr]{\C{have name : type by tactic}}

\begin{coq}{}{}
Lemma prime_above m : exists2 p, m < p & prime p.
Proof.
have m1_gt1: 1 < m`! + 1.
  by rewrite addn1 ltnS fact_gt0.
\end{coq}

Its syntax is similar to the one of the \C{Lemma} command: it takes a name, a
statement and starts a (sub) proof.  Since the proof is so short, we will
put it on the same line, and remove the full stop.

The next step is to use the \C{pdivP} lemma to gather a prime divisor of
\D{m`!.+1}.  We end up with the following, rather unsatisfactory, script.

\begin{coq}{}{}
Lemma prime_above m : exists2 p, m < p & prime p.
Proof.
have m1_gt1: 1 < m`! + 1 by rewrite addn1 ltnS fact_gt0.
case: (pdivP m1_gt1) => [p pr_p p_dv_m1].
\end{coq}

It is unsatisfactory because in our paper proof what plays an
interesting role is the \C{p} that we obtain in the second line,
and not the \C{m1_gt1} fact we proved as an intermediate fact.

We can resort to the flexibility of \C{have} to obtain a more
pertinent script: the first argument to \C{have}, here a name, can
actually be any introduction pattern, i.e. what follows
the \C{=>} operator, for example a view application.
At the light of that, the script can be
rearranged as follows.

\begin{coq}{}{}
Lemma prime_above m : exists2 p, m < p & prime p.
Proof.
have /pdivP[p pr_p p_dv_m1]: 1 < m`! + 1 by rewrite addn1 ltnS fact_gt0.
exists p => //; rewrite ltnNge; apply: contraL p_dv_m1 => p_le_m.
by rewrite dvdn_addr ?dvdn_fact ?prime_gt0 // gtnNdvd ?prime_gt1.
Qed.
\end{coq}

Here the first line obtains a prime \C{p} as desired, the second
one begins to show it fits by contrapositive reasoning, and the
third one, already commented in section~\ref{sec:quantifiedst}, concludes.

As a general principle, in the proof script style we propose, a full
line should represent a meaningful reasoning step (for a human being).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbsubsection{Order and max, a matter of symmetry}\label{sec:leqmax}
\index[concept]{forward reasoning}
\index[concept]{symmetric argument}

It is quite widespread in paper proofs to appeal to the reader's intelligence
pointing out that a missing part of the proof can be obtained by symmetry.
The worst thing one can do when formalizing such an argument on a computer
is to use the worst invention of computer science: copy-paste.  The language of
\Coq{} is sufficiently expressive to model symmetries, and the
Ssreflect proof language provides facilities to write symmetric arguments.

We prove the following characterization of the max of two natural numbers:
\[
\forall n_1, n_2, m, \quad m \le \max(n_1,n_2)
\Leftrightarrow m \le n_1 \textrm{ or } m \le n_2
\]

The proof goes as follows: Without loss of generality we can assume that
$n_2$ is greater or equal to $n_1$, hence $n_2$ is the maximum between
$n_1$ and $n_2$.  Under this assumption it is sufficient to check
that $m \le n_2$ holds iff either $m \le n_2$ or $m \le n_1$.
The only non-trivial case is when we suppose $m \le n_1$ and
we need to prove $m \le n_2$, which holds by transitivity.\hfill$\square$

As usual we model double implication as an equality between two
boolean expressions:

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
\end{coq}

The proof uses the following lemmas.  Pay attention to the premise of
\C{orb_idr}, which is an implication.

\begin{coq}{}{title=Tools}
Lemma orb_idr (a b : bool) : (b -> a) -> a || b = a.
Lemma maxn_idPl {m n} : reflect (maxn m n = m) (n <= m).
Lemma leq_total m n : (m <= n) || (n <= m).
\end{coq}

Our first attempt takes no advantage of the symmetry argument:
we reason by cases on the order relation,
we name the resulting fact on the same line
(it eases tracking where things come from) and we solve the two
goals independently.

\begin{coq}{}{}
Proof.
case/orP: (leq_total n2 n1) => [le_n21|le_n12].
  rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
  by apply: leq_trans le_mn2 le_n21.
rewrite maxnC orbC.
rewrite (maxn_idPl le_n12) orb_idr // => le_mn1.
by apply: leq_trans le_mn1 le_n12.
Qed.
\end{coq}

After line 2, the proof status is the following one:

\begin{coqout}{}{title=Output line 2}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
========================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

The first goal is simplified by
rewriting with \C{maxn_idPl} (as we did in section~\ref{sec:viewtac}).
Then \C{orb_idr} trivializes the main goal and generates a side condition with
an extra hypothesis we name \C{le_mn2}.

\begin{coqout}{}{title=Output before line 3,width=6.7cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
========================
(m <= n1) = (m <= n1) || (m <= n2)

subgoal 2 is: ...
\end{coqout}
\begin{coqout}{}{title=Output after 3,width=5.3cm}
2 subgoals
m, n1, n2 : nat
le_n21 : n2 <= n1
le_mn2 : m <= n2
========================
m <= n1

subgoal 2 is: ...
\end{coqout}

Line 4 combines by transitivity the two hypotheses to conclude.  Since it closes the
proof branch we use the prefix \C{by} to asserts the goal is solved and
visually signal the end of the paragraph.  Line 5 commutes \C{max} and \C{||}.
We can then conclude by copy-paste.


To avoid copy-pasting, shrink the proof script and finally make the
symmetry step visible we can resort to the \C{have} tactic.
In this case the statement is a variation of what we need to prove.
Remark that as for \C{Lemma}, we can place parameters, \C{x} and \C{y}
here, before the \C{:} symbol.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
have th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  move=> le_yx; rewrite (maxn_idPl le_yx) orb_idr // => le_my.
  by apply: leq_trans le_my le_yx.
by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
Qed.
\end{coq}

The proof for the \C{th_sym} sub proof is the text we copy-paste in the
previous script, while here it is factored out.
Once we have such extra fact in our context we reason by cases on
the order relation and we conclude.  Remark that the last line instantiates
\C{th_sym} \emph{in each branch} using the corresponding
hypothesis on \C{n1} and \C{n2} generated by the case analysis.
As expected the two instances are symmetric.

\begin{coqout}{}{}
2 subgoals
m, n1, n2 : nat
th_sym : forall x y : nat,
         y <= x -> (m <= maxn x y) = (m <= x) || (m <= y)
========================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)

subgoal 2 is:
(m <= maxn n2 n1) = (m <= n2) || (m <= n1) ->
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}
This is exactly what is needed in the first branch of the case analysis.
The last subgoal just requires commuting \C{max} and \C{||}.

We can further improve the script.  For example we could rephrase
the proof putting in front the justification of the symmetry, and
then prove one case when we pick $x$ to be smaller than $y$.

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
suff th_sym x y: y <= x -> (m <= maxn x y) = (m <= x) || (m <= y).
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
move=> le_yx; rewrite (maxn_idPl le_yx) orb_idr // => le_my.
by apply: leq_trans le_my le_yx.
Qed.
\end{coq}
\index[ssr]{\C{suff} also \C{suffices}}
The \C{suff} tactic (or \C{suffices})
is like \C{have} but swaps the two goals.

Note that here the sub proof is now the shortest paragraph.
This is another recurrent characteristic of the proof script style
we adopt in the \mcbMC{} library.

There is still a good amount of repetition in the current script.
In particular the main conjecture has been almost copy-pasted in
order to invoke \C{have} or \C{suff}.  When this repetition
is a severe problem, i.e. the statement to copy is large, one
can resort to the \C{wlog} tactic (or \C{without loss}).

\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
wlog le_n21: n1 n2 / n2 <= n1  => [th_sym|].
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
rewrite (maxn_idPl le_n21) orb_idr // => le_mn2.
by apply: leq_trans le_mn2 le_n21.
Qed.
\end{coq}
\index[ssr]{\C{wlog} also \C{without loss}}

Remark how \C{wlog} only needs the statement of the extra assumption,
and which portion of the context needs to be abstracted, here \C{n1} and
\C{n2}.  The sub goal to be proved is the following one.

\begin{coqout}{}{}
2 subgoals
m, n1, n2 : nat
th_sym : forall n1 n2 : nat, n2 <= n1 ->
           (m <= maxn n1 n2) = (m <= n1) || (m <= n2)
========================
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)


subgoal 2 is:
(m <= maxn n1 n2) = (m <= n1) || (m <= n2)
\end{coqout}

To keep the script similar to the previous one, we named explicitly
\C{th_sym}, to better link the final script to the previous attempts.
This is rarely the case in proof scripts of the library, since one typically
uses the \C{/(_ ...)} intro pattern to specialize the top of the stack.

Shrinking proof scripts is a never ending game.  The impatient reader can
jump to the next section to see
how intro patterns can be used to squeeze the last two lines into a
single one.  In the end, this proof script consists of three steps:
the remark that we can
assume \C{(n2 <= n1)} without losing generality; its justification in
terms of totality of the order relation and commutativity of \C{max}
and \C{||}; and the final proof, by transitivity, in the case when
the \C{max} is \C{n1} due to the extra assumption.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEVEL{1}
\mcbsubsubsection{Partially applied views}

A less important, but very widespread, feature of the Ssreflect
proof language can be used to shrink the proof even further.
In this proof script, we have named the fact \C{le_mn2} only for the
purpose of referring to this fact in the transitivity step.


\begin{coq}{}{}
Lemma leq_max m n1 n2 : (m <= maxn n1 n2) = (m <= n1) || (m <= n2).
Proof.
wlog le_n21: n1 n2 / n2 <= n1 => [th_sym|].
  by case/orP: (leq_total n2 n1) => /th_sym; last rewrite maxnC orbC.
by rewrite (maxn_idPl le_n21) orb_idr // => /leq_trans->.
Qed.
\end{coq}

Remember that the statement of
\C{leq_trans} is \C{(forall c a b, a <= c -> c <= b -> a <= b)} and
we have used it to transform the top assumption \C{(m <= n2)}.  Note that
the \C{leq_trans} expects a second proof argument, and that its type
would fix \C{b}, that is otherwise unspecified.  If one puts a
full stop just before the terminating \C{->}, to see the output of
the view application, one sees the following stack:

\begin{coq}{}{}
(forall n, n1 <= n -> m <= n) -> m <= n1.
\end{coq}

Rewriting the top assumption fixes \C{n} to \C{n1}, trivializes
the goal \C{(m <= n1)} to \C{true} and opens a trivial side
condition \C{(n2 <= n1)}.

The very compact idiom \C{/leq_trans->} is quite frequent in the
\mcbMC{} library.

%%%%%%%%%%%%%%%5
\mcbLEVEL{1}
\mcbsubsection{Euclidean division, simple and correct}\label{sec:edivn}
\index[concept]{simplifying equation}

Euclidean division is defined as one expects: iterating subtraction.

\begin{coq}{}{}
Definition edivn_rec d :=
  fix loop m q := if m - d is m'.+1 then loop m' q.+1 else (q, m).

Definition edivn m d := if d > 0 then edivn_rec d.-1 m 0 else (0, m).
\end{coq}
\index[coq]{\C{fix}}

The \C{fix} keyword lets one write a recursive function locally, without
providing a global name as \C{Fixpoint} does.  This also means that \C{d}
is a parameter of \C{edivn_rec} that does not change during recursion.
The \C{edivn} program handles the case of a null divisor, producing
the dummy pair \C{(0,m)} for the quotient and the reminder respectively.

We start by showing the following equation.

\begin{coq}{}{}
Lemma edivn_recE d m q :
 edivn_rec d m q = if m - d is m'.+1 then edivn_rec d m' q.+1 else (q,m).
Proof. by elim: m. Qed.
\end{coq}
\index[concept]{unfolding equation}
It is often useful to state and prove unfolding equations like this one.
When the simplification tactic \C{/=} unfolds too aggressively,
rewriting with such equations gives better control on how many
unfold steps one performs.

The statement of our theorem
uses a let-in construct (remark the \C{:=} sign)
to name an expression used multiple
times, in this case the result of the division of \C{m} by \C{d}.

\begin{coq}{}{}
Lemma edivnP m d (ed := edivn m d) :
  ((d > 0) ==> (ed.2 < d)) && (m == ed.1 * d + ed.2).
Proof.
\end{coq}

As one expects, \C{edivn} being a recursive program, its specification
needs to be proved by induction.  Given that the recursive call is on
the subtraction of the input, we need to perform a strong induction,
as we did for the postage example in section~\ref{sec:strongind}.

Bet let's start by dealing with the trivial case of a null divisor.

\begin{coq}{}{}
case: d => [//=|d /=] in ed *.
rewrite -[edivn m d.+1]/(edivn_rec d m 0) in ed *.
rewrite -[m]/(0 * d.+1 + m).
elim: m {-2}m 0 (leqnn m) @ed => [[]//=|n IHn [//=|m]] q le_mn.
rewrite edivn_recE subn_if_gt; case: ifP => [le_dm|lt_md]; last first.
  by rewrite /= ltnS ltnNge lt_md eqxx.
have /(IHn _ q.+1) : m - d <= n by rewrite (leq_trans (leq_subr d m)).
by rewrite /= mulSnr -addnA -subSS subnKC.
Qed.
\end{coq}
\index[ssr]{\C{tactic in name}}
Line 1 handles the case of \C{d} being zero.  The ``\C{in E...}'' suffix
can be appended to any tactic in order to push on the stack the specified
hypotheses before running the tactic and pulling
them back afterwards (see~\cite[section 6.5]{ssrman}).
The \C{*} means that the goal is also affected by the tactic, and not just
the hypotheses explicitly selected.

Lines 2 and 3 prepare the induction by unfolding the definition of
\C{edivn} (to expose the initial value of the accumulators of \C{edivn_rec})
and makes the invariant of the division loop explicit replacing
\C{m} by \C{(0 * d.+1 + m)}.  Recall the case \C{d} being \C{0} has
already been handled.

Line 4 performs a strong induction, also generalizing the initial
value of the accumulator \C{0}, leading to the following goal:

\begin{coqout}{}{}
d, n : nat
IHn : forall m n0 : nat, m <= n ->
      let ed := edivn_rec d m n0 in
        (ed.2 < d.+1) && (n0 * d.+1 + m == ed.1 * d.+1 + ed.2)
m, q : nat
le_mn : m < n.+1
========================
let ed := edivn_rec d m.+1 q in
  (ed.2 < d.+1) && (q * d.+1 + m.+1 == ed.1 * d.+1 + ed.2)
\end{coqout}
Note that the induction touches variables used in \C{ed} that
is hence pushed on the goal stack.  The \C{@} modifier tells Ssreflect
to keep the body of the let-in.

Line 5 unfolds the recursive function and uses the following lemma to push the
subtraction into the branches of the if statement. Then it reasons by cases
on the guard of the if-then-else statement.
%\marginnote{Should we embed this lemma in the unfolding equation?}

\begin{coq}{}{}
Lemma subn_if_gt T m n F (E : T) :
  (if m.+1 - n is m'.+1 then F m' else E) =
    (if n <= m then F (m - n) else E).
\end{coq}

The else branch corresponds to the non-recursive case of
the division algorithm and is trivially solved in line 6.
The recursive call is done on \C{(m-d)}, hence the need for a strong
induction.  In order to satisfy the premise of the induction hypothesis,
line 7 shows that \C{(m - d <= n)}.  Line 8 concludes.

% \section{STOP HERE}
%
% THIS CHAPTER IS ABOUT METHODOLOGY, plus introduces the other logical
% connectives. May be merged into the previous chapter.
%
%
% % Where one learns to do proofs.
% % Boolean reflection in practice, views, discussion on the definition of leq,
% % proofs on things defined in the
% % previous chapter, associated tactics, exercises on prime, div,
% % binomial, etc.
% %
% % spec? A new vernacular to declare specs without typing coinductive and
% % by writing explicitly the equations.
%
% Discussion prop/bool, intuitionism, extraction (we should be able to
% avoid talking about impredicativity, but use Prop for computationally
% irrelevant).
%
%
% \begin{itemize}
% \item can we specify all we have written so far using just = and forall? No.
% 	Example dvdn needs exists to be specified
% \item exists, and, or, neg, False, True as inductives (again CH style)
% \item related tactics: split, left, right,exists,case
% \end{itemize}
%
% Anyway to take advantage of computation (ssr style) we want to
% work with bool as much as possible:
%
% \begin{itemize}
% \item reflect is the right way to write iff, <->, specialized to bool
% 	so that the proof language recognizes it and offer a bit more ergonomic
% \item is-true
% \item infrastructure for reflect: iffp, altp
% \item no split if goal is \&\& (metodology)
% \end{itemize}
%
% Writing good statements
%
% \begin{itemize}
% \item = as iff for bool, because rewrite is easy to use
% \item and3p, spec (drive your proof),
% \item advanced stuff: classically P instead of not-not P (can be
%   skipped for beginners)
% \item in general good quantifications and implicit arguments and good library
% 	makes it possible to work without evars
% \item . \C{<=} . ?= iff .
% \end{itemize}
%
% Statements do also occur in the middle of proofs.  There we have many ways to
% write them compactly, wlog and have.
%
% Comparison with other possible ways of writing properties:
% \begin{itemize}
% \item impact of le v.s. leq in a proof
% \end{itemize}
%
% In this chapter we should distill a description of our
% systematic-reactions, reflexes, to typical situations a
% beginner would screw up. In fact it would be great to explain here the
% mix of Gallina (unless, classically, etc.) and of tactics (wlog,
% have,...) that lead to a convenient modelling of the math prose.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \mcbLEARN{Declaring implicit arguments}
% \mcbREQUIRE{Canonical}
% \mcbPROVIDE{stating lemmas}
% \mcbLEVEL{2}
% \mcbsection{Declaring implicit arguments}\label{sec:declaringimpl}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% here we describe how to choose which arguments are implicit,
% that one has to think ahead how  a lemma is used and hence
% which data type inference has at hand.  Also that the order
% of quantifiers is relevant.
% \begin{itemize}
% \item lemmas: fwd/backward reasoning
% \item equations, look at the concl too, free vars are abstracted
% \item compare with eapply style
% \end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\mcbLEARN{Coercions}
\mcbREQUIRE{}
\mcbPROVIDE{}
\mcbLEVEL{1}
\mcbsection{Notational aspects of specifications}
\label{sec:coercions}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Even if the main way to extend the type inference algorithm
% is via Canonical Structures, another mechanism is available
% and used all over the library, even if it plays a minor role.
% The language of Canonical Structures lets one program how the value of
% an implicit argument can be synthesized, but can hardly be used to
% explain \Coq{} how to ``fix'' an ill-typed term written by the user.

When a typing error arises, it always involves three objects:
a term \lstinline/t/, its type \lstinline/ity/ and the type
expected by its context \lstinline/ety/.  Of course, for this
situation to be an error, the two types \lstinline/ity/ and
\lstinline/ety/ do not compare as equal.
The simplest way one has to explain \Coq{} how to fix \lstinline/t/,
is to provide a functional term \lstinline/c/ of type
\lstinline/(ity -> ety)/ that is inserted around \lstinline/t/.
In other words, whenever the user writes \lstinline/t/ in a context
that expects a term of type \lstinline/ety/, the system instead of
raising an error replaces \lstinline/t/ by \lstinline/(c t)/.

A function automatically inserted by \Coq{} to prevent a type
error is called \emph{coercion}.
The most pervasive coercion in the \mcbMC{} library is
\lstinline/is_true/ one that lets one write statements using boolean
predicates.
\index[concept]{coercion}

\begin{coqdef}{name=istrue}
Lemma example : prime 17.
Proof.
Set Printing Coercions. Redirect "g1" Show.
by [].
Qed.
\end{coqdef}
\begin{coq}{def=istrue}{width=6cm}
Lemma example : prime 17.
$~$
$~$
\end{coq}
\coqrun{name=r3}{ssr,istrue}
\begin{coqout}{run=r3;out=g1}{title=Goal fully printed,width=6cm}
========================
is_true (prime 17)
\end{coqout}

When the statement of the example is processed by \Coq{}
and it is enforced to be a type, but \lstinline/(prime 17)/ is actually
a term of type \lstinline/bool/.  Early in the library the
function \lstinline/is_true/ is declared as a coercion from
\lstinline/bool/ to \lstinline/Prop/ and hence is it inserted
by \Coq{} automatically.

\begin{coq}{name=istruedef}{}
Definition is_true b := b = true.
Coercion is_true : bool >-> Sortclass. (* Prop *)
\end{coq}

Another coercion that is widely used injects booleans into naturals.
Two examples follow:

\begin{coq}{name=natofbool}{}
Fixpoint count (a : pred nat) (s : seq nat) :=
  if s is x :: s' then a x + count a s' else 0.
Lemma count_uniq_mem (s : seq nat) x :
  uniq s -> count (pred1 x) s = has (pred1 x) s.
\end{coq}
\coqrun{name=ex}{ssr,istruedef,natofbool,abort}
where \C{pred T} is a notation for the type  \C{T -> bool} of boolean
predicates.
\index[coq]{\C{pred} (predicate)}
\index[coq]{\C{[pred .. | ..]}|seealso {\C{pred} (predicate)}}


At line number 2 the term \lstinline/(a x)/ is a boolean.  The
\lstinline/nat_of_bool/ function is automatically inserted to turn
\lstinline/true/ into \C{1} and \lstinline/false/ into \lstinline/0/.
This notational trick is reminiscent of Kronecker's $\delta$ notation.
Similarly, in the last line the membership test is turned into
a number, that is shown to be equivalent to the count of any
element in a list that is duplicate free.

% Another example of a coercion that is related to the running example
% of the current chapter is \lstinline/sort/.  Typically the projection
% of a record type extracting the data type is declared as a coercion
% letting one state generic theorems like in the following example.
%
% \begin{coqdef}{name=sotc}
% Lemma example (e : eqType) : forall x y : e, x == y -> y == x.
% \end{coqdef}
% \begin{coq}{def=sotc}{}
% Lemma example (e : eqType) : forall x y : e, x == y -> ...
% \end{coq}
% \coqrun{name=r5}{ssr,sotc,abort}
%
% Here the type of \lstinline/x/ and \lstinline/y/ is
% \lstinline/(sort e)/ and not \lstinline/e/ as the user initially wrote.
% Indeed \lstinline/e/ is a term (of type \lstinline/eqType/) while
% the \lstinline/forall/ quantification expects a type after the
% colon.  The \lstinline/sort/ function mapping an \lstinline/eqType/
% into a \lstinline/Type/ is inserted automatically.

Coercions are composed transitively.

\begin{coq}{name=b2z}{}
Definition zerolist n := mkseq (fun _ => 0) n.
Coercion zerolist : nat >-> seq.
Check 2 :: true == [:: 2; 0].
\end{coq}
\coqrun{name=r6}{ssr,b2z}

For the convenience of the reader we list here the most widely
used coercions. There are also a bunch on Funclass not listed
and elimT surely deserves some explanation.

\noindent
\begin{tcolorbox}[colframe=blue!60!white,before=\hfill,after=\hfill,center
	title,tabularx={l|l|l},fonttitle=\sffamily\bfseries,title=Coercions]
coercion & source & target \\ \hline
\lstinline/Posz/ & \lstinline/nat/ & \lstinline/int/ \\
\lstinline/nat_of_bool/ & \lstinline/bool/ & \lstinline/nat/ \\
\lstinline/elimT/ & \lstinline/reflect/ & \lstinline/Funclass/ \\
\lstinline/isSome/ & \lstinline/option/ & \lstinline/bool/ \\
\lstinline/is_true/ & \lstinline/bool/ & \lstinline/Sortclass/ \\
\hline
\end{tcolorbox}

% \marginnote{This may go in Chapter 1}
% Another device that is used to help type inference is the
% \lstinline/Implicit Types/ directive.  This directive lets
% one attach a default type to variable names.
%
% \begin{coq}{name=itype}{title=Example of \lstinline/Implicit Types/}
% Implicit Types m n : nat.
% Check forall m n, n == m.
% \end{coq}
% \coqrun{name=r7}{ssr,itype}
%
% In the example above the statement we \lstinline/Check/ does not
% contain enough information alone to be well types.  The overloaded
% \lstinline/==/ notation needs the terms to which it is applied to
% have a type for which a \lstinline/Canonical Structure/ is declared.
% Even if we did not annotate \lstinline/n/ and \lstinline/m/ with a
% type, the directive on the first line does it for us.

The reader already familiar with the concept of coercion
may find the presentation of this chapter nonstandard.
Coercions are usually presented as a device to model
subtyping in a theory that, like the \mcbCIC{}, does not
feature subtyping.  As we will see in chapter~\ref{ch:hierarchy}
the role played by coercions in the modelling of the hierarchy
of algebraic structures is minor.  The job of
coercions in that context is limited to
forgeting some fields of a structure to obtain a simpler one, and
that is easy.  What
is hard is to reconstruct the missing fields of a structure
or compare two structures finding the minimum super structure.
These tasks are mainly implemented with programming type inference.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Exercises}

%%%%%%%%
\begin{Exercise}[label=ex:iffp,difficulty=0,title={reflect}]
Prove the following lemmas.  In particular prove the first
one with and without using \C{iffP}.

\begin{coq}{}{}
Lemma iffP_lr (P : Prop) (b : bool) :
  (P -> b) -> (b -> P) -> reflect P b.
Lemma iffP_rl (P : Prop) (b : bool) :
  reflect P b -> ((P -> b) /\ (b -> P)).
\end{coq}
\end{Exercise}

%%%%%%%
\begin{Exercise}[label=ex:eqnP,difficulty=0,title={eqnP}]
Finish this proof.

\begin{coq}{}{}
Lemma eqnP n m : reflect (n = m) (eqn n m).
Proof.
apply: (iffP idP).
\end{coq}
\end{Exercise}


%%%%%%%
\begin{Exercise}[label=ex:eqnPinj,difficulty=0,title={Injectivity to nat}]
Finish this proof.

\begin{coq}{}{}
Lemma nat_inj_eq T (f : T -> nat) x y :
  injective f -> reflect (x = y) (eqn (f x) (f y)).
Proof.
move=> f_inj; apply: (iffP eqnP).
\end{coq}
\end{Exercise}

%%%%%%%
\begin{Exercise}[label=ex:maxnidP,difficulty=0,title={Characterization of max}]
Prove the following lemma.

\begin{coq}{}{}
Lemma maxn_idPl m n : reflect (maxn m n = m) (m >= n).
\end{coq}
\end{Exercise}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Solutions}

%%%%%%%%%%
\begin{Answer}[ref=ex:iffp]

\begin{coq}{}{}
Lemma iffP_lr (P : Prop) (b : bool) :
  (P -> b) -> (b -> P) -> reflect P b.
Proof.
by case: b => [_ H|H _]; [left; apply H | right=> p; move: (H p)].
(* with iffP: by move=> *; apply: (iffP idP). *)
Qed.

Lemma iffP_rl (P : Prop) (b : bool) :
  reflect P b -> ((P -> b) /\ (b -> P)).
Proof. by case: b; case=> p; split. Qed.
\end{coq}

\end{Answer}

%%%%%%%%%
\begin{Answer}[ref=ex:eqnP]

\begin{coq}{}{}
Lemma eqnP n m : reflect (n = m) (eqn n m).
Proof.
apply: (iffP idP) => [|->]; last by elim: m.
by elim: n m => [[]|n IH [//|m] /IH ->].
Qed.
\end{coq}

\end{Answer}


%%%%%%%
\begin{Answer}[ref=ex:eqnPinj]

\begin{coq}{}{}
Lemma nat_inj_eq T (f : T -> nat) x y :
  injective f -> reflect (x = y) (eqn (f x) (f y)).
Proof. by move=> f_inj; apply: (iffP eqnP) => [/f_inj|->]. Qed.
\end{coq}

\end{Answer}

%%%%%%%
\begin{Answer}[ref=ex:maxnidP]

\begin{coq}{}{}
Lemma maxn_idPl m n : reflect (maxn m n = m) (m >= n).
Proof.
by rewrite -subn_eq0 -(eqn_add2l m) addn0 -maxnE; apply: eqP.
Qed.

\end{coq}
\end{Answer}
