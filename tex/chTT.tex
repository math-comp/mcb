\chapter{Dependent Type Theory}{}
\label{ch:ttch}

%% Summary of the 22/02 discussion:

%% This chapter presents the foundational language used to formalize
%% mathematics. It is both about the dependent type theory, as an
%% alternative to say ZF set theory, and about the practice of
%% formalization in the Calculus of Inductive Constructions, as
%% implemented in the Coq proof assistant.

%% The use of dependent type theory, as opposed to set theory, imposes
%% some significant mind shifts, that we will try to illustrate.

%% First, set theory has two layers (language of sets + propositions on
%% one hand, 1st order deduction on the other). Here there is a single
%% one, based on the concept of types.

%% There is a single meta-statement, which is Gamma |- t : T which reads
%% t has type T (in context Gamma). Type T can be seen as a name for a
%% collection of terms, in which case, we can think of t : T as t \in
%% T. Although as we will see this image has limitations.

%% We start by describing informally the foundational language we will
%% use to write statements, i.e. terms and types (and thus typing
%% judgements). This is MLTT.

%% This language can be used to craft sentences expressing that some
%% terms are well-formed, like let n be a natural number, then n + n is
%% also a natural number. This is quite different from set-theory (3 is a topology).

%% In fact, the same language can be used to describe provability. If we
%% transform ':' into '\in' we get reasonable math sentences. But
%% beware, type are really well-formedness conditions, that can play
%% against you. Example of sets as types, then the solution: -> put types
%% at the right level, it is easier to sub-type than to super-type.

%% Note that so far, we have no ``axioms'', the really interesting part of
%% deduction. The analogue is inductives, which bring new language, and
%% equational theories via the definition of functions by
%% pattern-matching/fixpoints, and the reduction/conversion rule which
%% build rewrite systems. Conversion provides built-in automation wrt to these
%% rewrite systems. We could have more reduction than today.

%% With our provability glasses, we also have data-structures for
%% proofs. And we can say something about them (an example other than
%% Hedberg?). And see Homotopy Type Theory. But sometimes this is
%% annoying, for instance to define sub-types. One could have axioms. One
%% could use SProp (in the future). Here we take benefit of Hedberg to
%% have pleasant axiom-free subTypes. One can also craft specific inductives
%% to describe interesting proof structures. Typically case analysis. Example of
%% trichotomy? Boolean reflection is another example, which may also
%% bring some automation. More inductive specs to come in the
%% small scale reflection chapter.

% 8/4/2019

% 72 : remove natural deduction + add Check (fun ...) : forall ...
% 73 : remove matrix, cut bool_irrelevance
% 74 : between "inductive types" and "more connective" add a section
%      about dependent types (eg tuple, with examples and check)
% 77 : cut eq
% 78 : new section with eq and bool_irrelevance
% 78 : remove section 3.2
% 79 : new section about "formalizing in TT" where set <> Type:
       %% In fact, the same language can be used to describe provability. If we
       %% transform ':' into '\in' we get reasonable math sentences. But
       %% beware, type are really well-formedness conditions, that can play
       %% against you. Example of sets as types, then the solution: -> put types
       %% at the right level, it is easier to sub-type than to super-type.
       















%T he authors made the deliberate choice to postpone the presentation of
% the mathematical foundations of the \Coq{} system and the formal
% definition of its language. Instead, the previous chapters have
% dealt with the definition of (typed) programs and on the way these
% programs can be used to describe computable functions and decidable
% predicates. This take on calculations is indeed both at the core of
% the type theory underlying \Coq{} and one of the crucial ingredients
% to the methodology at the base of the \mcbMC{} library. The present chapter is
% devoted to a more in-depth presentation of these mathematical
% foundations, although an exhaustive description shall remain out of
% the scope of the present book.
% For more comprehensive presentations of
% type theory for formalized mathematics, the reader can refer to more
% specialized references like~\cite{ttfp}, or the
% shorter survey in the Handbook of Automated
% Reasoning~\cite[Volume 2, chapter 18]{handbook-ar}.

The formal language we use to write
mathematical statements and proofs in the \Coq{} proof assistant
is called \emph{Gallina}.
This language is an evolution of the \emph{\mcbCIC{}}
(CIC)~\cite{coquand:huet:88,CoPa89} implemented
by the early versions of \Coq{} in the 80's. In turn, CIC is one of the many
descendants of the intuitionistic type theory~\cite{ITT} Martin-Löf developed in
the 70's. In order to avoid ambiguities with other type theories we refer to
this family of formal systems using the term \emph{dependent type theory}.\\
In this
chapter, we provide some hints on the main features of this
formalism. The interested reader shall refer to the reference manual
of \Coq{}~\cite{Coq:manual} for a formal definition of Gallina. %% The first
%% chapter of the reference book on homotopy type theory~\cite{hottbook},
%% as well as its annex provide a gentle presentation of Martin-Löf
%% intentionnal type theory, which can be seen as a core subset of
%% Gallina.

%\section{Terms, types, proofs}\label{sec:chi}

\section{Propositions as types, proofs as programs}\label{sec:patpap}
% \emph{Dependent type theory}, in its several different flavors, can be used
% as a foundational language for mathematics. It thus provides an alternative
% to the flavors of set theory commonly invoked as the formal language of
% reference~\cite{bourbaki-sets}. Informally speaking, a
% set-theoretic framework has two stages. First order logic provides
% the former layer: it describes the language of logical sentences and how
% these statements can be combined and proved. This language is then
% used in the second layer, to formulate the axioms of the particular
% theory of interest. By contrast, proof assistants based on dependent
% type theory, like \Coq{}, embrace an approach coined
% \emph{propositions-as-types}~\cite{ch}, and use the same language of
% types in a uniform way to describe mathematical objects, mathematical
% assertions, and their proofs. 

Set theory is commonly invoked as the foundational language for
mathematics~\cite{bourbaki-sets}. Informally speaking, a
set-theoretic framework has two stages. First order logic provides
the former layer: it describes the language of logical sentences and how
these statements can be combined and proved. This language is then
used in the second layer to formulate the axioms of the particular
theory of interest, for example the ones of Zermelo-Fraenkel set theory.
By contrast, proof assistants based on a flavor of dependent
type theory, like \Coq{}, embrace an approach coined
\emph{propositions-as-types}~\cite{ch}, and use the same language of
types in a uniform way to describe mathematical objects, mathematical
assertions, and their proofs.  As we shall see, there is a significant 
difference in phrasing the rules dictating which sentences and proofs 
are well-formed.


In set theory the rules which govern the construction of
well-formed, grammatically correct, statements are rather loose.
For example
$x \in x$ is a valid sentence, where $x$ plays the role of
both an element and as set. Still, the
goal of the game is to construct a proof for a given well-formed
proposition, using first-order logic to combine the axioms of the
theory, and nonsensical sentences supposedly have no proof.

The first two chapters of the present book illustrate how
types can be used to help classify, and clarify expressions passed to
the checker. In fact, the language of types available in the Calculus
of Inductive Constructions, and thus in  \Coq{}, is so expressive that
\emph{logical statements} are identified with some \emph{types} and
their \emph{proofs} with \emph{terms}, or programs, having this
type. This way, proving a statement consists in fact in constructing a
term of the corresponding type. Objects of the formalism are programs,
and proofs are themselves objects of the formalism.

\marginpar{meta is condusing here: take more time to talk about this}
In this setting, the analogue of the meta-statement
that a given proposition has a proof is the meta-statement that a
given term has a given type. Such a meta-statement is called a
\emph{typing judgment}. It is a ternary relation written as follows:
% using the \emph{turnstile} $\vdash$ symbol:
$$\Gamma \vdash t : T$$
and reads:
\emph{in the context $\Gamma$, the term $t$ has the type $T$}. A type
is just a term, which is called a type when it occurs on the right
hand-side of a column in a well-formed typing judgment, like $T$ in
our case. A context is a list of variables, each paired with a type,
that can occur in $t$ and $T$. This typing judgment expresses that
under the typing assumptions listed in the context $\Gamma$, $t$ and
$T$ are well-formed, and moreover that term $t$ has type $T$. Example:

$$x : \mathbb{N} \vdash x + x : \mathbb{N}$$

A typing judgment is valid if it is justified by combining the \emph{typing rules} of the
type theory, up to atomic ones like this one:

$$x : T \vdash x : T$$

which asserts that a context assigns a type to each variable it contains.
A call to the \C{Check} command introduced in Chapter~\ref{ch:prog} 
verifies that a certain typing judgment holds in the current
context. For instance, term \C{3} has type \C{nat} in an empty context:

\begin{coq-left}{name=check-3}{}
Check 3 : nat.
\end{coq-left}
\begin{coqout-right}
3 : nat
\end{coqout-right}
\coqrun{name=r1}{ssr,check-3}

The context of a typing judgment includes all the variables and
hypothesis currently assumed, and validate these assumptions.
For instance, in a context containing a certain variable \C{n} with
type \C{nat}, the term \C{n + n} has type \C{nat}:

\begin{coq-left}{name=check-nn}{}
Variable n : nat.
Check n + n : nat.
\end{coq-left}
\begin{coqout-right}
n + n : nat
\end{coqout-right}
\coqrun{name=r2}{ssr,check-nn}

And \Coq{} complains if we try to verify the typing judgment asserting it
has type \C{bool}. In this case, it even computes and displays the
correct type:

\begin{coq-left}{name=check-nnbool}{}
Fail Check n + n : bool.

\end{coq-left}
\begin{coqout-right}
The term "n + n" has type "nat" while it is expected to have type "bool".
\end{coqout-right}
\coqrun{name=r2}{ssr,check-nnbool}

Our last example is a typing judgment  $\Gamma \vdash t : T$ where
the term $t$ is a proof. Indeed, again in a context containing a
variable \C{n} of type \C{nat}, the term
\C{(muln0 n)} has type \C{n * 0 = 0} and is thus a proof of the
corresponding equational assertion:

\begin{coq-left}{name=check-negb}{}
Variable n : nat.
Check muln0 n : n * 0 = 0.

\end{coq-left}
\begin{coqout-right}
muln0 n : n * 0 = 0
\end{coqout-right}
\coqrun{name=r2}{ssr,check-muln0}

The context of a typing judgment logs all the variables and the facts
currently assumed.

% Maybe move to the next section?
%  It also registers the definitions available, like in:

% \begin{coq}{}{}
% Definition foo : nat := 1.
% Definition bar (n : nat) : bool := n == 0.
% \end{coq}
% Type annotations may be omitted when there is enough information to
% infer them. However, as a rule of thumb, it is usually a good practice
% to keep them for documentation purposes.



\section{Terms, types, sorts}\label{sec:terms}

This section makes more precise what contexts, terms and types
are. Note that the description is restricted to a subset of Gallina,
for the sake of the exposition. We refer again the reader looking for
an exhaustive description to the corresponding chapter of \Coq{}'s
reference manual~\cite{Coq:manual}.

As alluded to in the introduction, type theory avoids the distinction
set theory makes between sets and propositions: type theory is based
on a same and single collection of inductively defined terms. A
judgment $\Gamma \vdash t : T$ relates two \emph{terms}, $t$ and $T$ (in the
context $\Gamma$), and $T$ is called a \emph{type} because it appears
on the right of the column symbol in a typing judgment. Term $T$ can be
thought of as a label for a collection of terms, and the judgment
$\Gamma \vdash t : T$, as the statement that (in context $\Gamma$)
``term $t$ belongs to the collection $T$'', or even, to some extent,
$t\in T$. 
For instance, we have used in previous example assumptions of the
form \C{n : nat} to model the sentence ``let $n$ be a natural number''.

This set-theoretic analogy should be taken with a pinch of salt
though. First, there is no way in type theory to introduce a term, even
a variable, without simultaneously introducing its type. Things are
different in set theory, where an object $a$ can be constructed without
necessarily being casted as being the element of a super-set
$A$. Second, a judgment is not a proposition in the same sense as the
set-theoretic sentence $t \in T$ would be. In particular, one cannot
reason (internally) by case analysis on the meta-proof that
$t$ has type $T$, nor can we disprove (internally) that $t$ has type $T$ for some particular
$T$. Finally, as we shall see later in this section, substitution of
equals does not behave the same for terms at the left of a column, and
for those on the right ---types.


We assume a collection of distinct names, used to denote atomic terms
and called \emph{sorts}.  One of this sorts is called \C{Prop}, and it
is the type of statements:

\begin{coq-left}{name=check-eq}{}
Check 7 = 7 : Prop.
\end{coq-left}
\begin{coqout-right}
7 = 7 : Prop
\end{coqout-right}
\coqrun{name=r2}{ssr,check-eq}

As noted already in Chapter~\ref{ch:proofs}, a well formed statement
is not necessary a provable one:

\begin{coq-left}{name=check-eq}{}
Check 7 = 9 : Prop.
\end{coq-left}
\begin{coqout-right}
7 = 9 : Prop
\end{coqout-right}

Types used as data-structures, to represent mathematical objects (as
opposed to mathematical assertions), live in a distinct sort named
\C{Set}:

\begin{coq-left}{name=check-nat}{}
Check nat : Set.
\end{coq-left}
\begin{coqout-right}
nat : Set
\end{coqout-right}
\coqrun{name=r2}{ssr,check-nat}

Gallina moreover features a countable, cumulative hierarchy of sorts,
displayed as \C{Type} and indexed by an integer variable which is by
default hidden to the user.  In the following typing judgment we tell Coq
to print the index of \C{Type}:

\begin{coq-left}{name=check-prop}{}
Set Printing Universes.
Check Type : Type.
\end{coq-left}
\begin{coqout-right}
$~$
Type@{U1} : Type@{U2} (* U1 < U2 *)
\end{coqout-right}

the instance of \C{Type} on the right side of the column has a greater
index (named \C{U2} here) than the instance of \C{Type} on the left.

In an empty context,
the term \C{Prop} has type \C{Type} (for any value of the index) :

\begin{coq-left}{name=check-prop}{}
Check Prop : Type.
\end{coq-left}
\begin{coqout-right}
Prop : Type@{U3} (* Prop < U3 *)
\end{coqout-right}
\coqrun{name=r2}{ssr,check-prop}

Similarly, \C{Set} has type \C{Type}:

\begin{coq-left}{name=check-set}{}
Check Set : Type.
\end{coq-left}
\begin{coqout-right}
Set : Type@{U4} (* Set < U3 *)
\end{coqout-right}
\coqrun{name=r2}{ssr,check-set}

\noindent
\C{Set} is a name for the smallest element of the hierarchy of \C{Type}s.

Terms \C{nat}, \C{bool}, \C{Prop} are simple, atomic types, which can be used
to build non-atomic ones. For instance, in Chapter~\ref{ch:proofs}, we
met the type of functions from natural numbers to boolean, which is:

\begin{coq}{name=check-bool-nat}{}
Check nat -> bool : Type.
\end{coq}

Similarly the type of addition over natural numbers is 
\C{nat -> nat -> nat}, and the type of boolean negation is 
\C{bool -> bool}.

In Chapter~\ref{ch:prog}, we used a \emph{polymorphic} type to represent
sequences of elements:

\begin{coq}{name=seq_def}{}
Inductive seq (A : Type) := nil | cons (hd : A) (tl : seq A).
\end{coq}
\coqrun{name=seq_run}{seq_def}

Since \C{seq} builds a new type for each given instance of its
parameter, it has the type of a function:

\begin{coq}{name=check-seq}{}
Check seq : Type -> Type.
\end{coq}

Non-atomic terms are defined from a countable infinite set of
symbols, called  \emph{variables}.
It is thus always possible to exhibit a new variable
distinct from a given arbitrary finite collection of variables. In \Coq{}
syntax, we can use letters, or more generally sequences of
alpha-numeric characters, to represent variables. For instance, the
following command declares two variables of type \C{nat}, i.e. two
natural numbers and one of type \C{seq nat}, i.e. a list of numbers:

\begin{coq}{}{}
Variables (n m : nat) (l : seq nat).
\end{coq}

Hypotheses are themselves variables, whose type represent the
assumed statement. The following line assumes a hypothesis:

\begin{coq}{}{}
Hypothesis neq0 : n = 0.
\end{coq}
But it is just a synonym, with a more suggestive name, of:
\begin{coq}{}{}
Variable neq0 : n = 0.
\end{coq}

Of course, it is only possible to extend the current context with variables, or
hypotheses, or definitions, with a well-formed type. As we have seen
so far, well-formed types include atomic types, like \C{nat} or
\C{Prop}, and function types like \C{nat -> bool}. In Gallina, it is
also possible to define functions which build a \emph{type} for any
\emph{value} of a given datatype:
\begin{coq}{name=check-deptype}{}
Variable t : nat -> Type.
\end{coq}

Term \C{t} is called a \emph{dependent type}, as it constructs a
family of types which depend on a parameter in a data type. For
instance, \C{t} could be the type of lists of booleans with a
prescribed length, \C{t n} being the type of lists of length
\C{n}. Now such a dependent type can itself be used as the return type
of a function, like in: 

\begin{coq}{name=check-depfun}{}
Variable g : forall n : nat, t n.
\end{coq}

For instance, \C{g n} could build the list of length \C{n} containing
only \C{true} elements.
Thus in Gallina, the return type of a function may depend on the
\emph{value} of its argument: the prefix \C{forall n,} part of the
type of \C{g} is a binder, which allows to describe the dependency in
the return type. A type of the form \C{forall x, T} is called a
\emph{product type}, or sometimes a $\Pi$-type. Note that a product
type \C{forall x, T} is well-formed for any \C{T} of type \C{Type},
\C{Set} or \C{Prop}, even when \C{T} does not depend on \C{x}. In this
case, when the return type is constant in the argument, the product
type is displayed with an arrow, as in:
\index[concept]{dependent function space}

\begin{coq-left}{name=check-non-dep}{}
Check forall x : nat, bool : Type.
\end{coq-left}
\begin{coqout-right}{name=check-non-dep}{}
nat -> bool : Type
\end{coqout-right}
  
A term with a product (or arrow) type is a function, in the sense that
it can be \emph{applied} to an argument, provided that the type of
this argument agrees with the source of the function type:

\begin{coq}{}{}
Variable f : nat -> bool.
Check f 3 : bool.
Fail Check f true : bool.

(* g : forall n, t n *)
Check g 3 : t 3.
\end{coq}

The typing rule governing the application of functions to arguments is
a emblematic example of the strict well-formedness conditions enforced
by types on mathematical statements. This rule will rule out
nonsensical assertions, like ``$\pi$ is equilateral'' or ``2 is a
Banach space''. But the same rule shall also play a nastier role, for
instance if the user wants to casually embed natural numbers into
integers, and integer into rational numbers: working with these
obvious inclusions might require an explicit cast in a typed setting,
if $\mathbb{N}$, $\mathbb{Z}$, $\mathbb{Q}$ are represented by
distinct types.


New functions are defined by \emph{abstracting} a variable in a term,
as discussed in Chapter~\ref{ch:prog}. The resulting term has a
product (or an arrow) type:

\begin{coq}{}{}
Definition bar (n : nat) : bool := 
  n == 0.
Check bar : nat -> bool.
\end{coq}

Term \C{bar} has type \C{nat -> bool} because in the current context,
augmented with a variable declaration \C{n : nat}, corresponding to
the name and type of the argument, the body \C{n == 0} of the definition
 has type \C{bool}.

As we have seen in Chapter~\ref{ch:prog}, a function is defined by
\emph{binding} its argument in the body of its definition: in
\C{bar}, the variable \C{n}, on the left of the \C{:=} delimiter, is
bound in the body of the definiion, the \C{n} on the right of the \C{:=}
delimiter. When a defined function is applied to its argument, the
resulting term is \emph{computed} by substituting the bound variable
for the value of the argument.

\begin{coq-left}{}{}
Definition bar (n : nat) : nat := n.
Print bar.
Compute bar 4.
\end{coq-left}
\begin{coqout-right}
bar = fun n => n
    : nat -> nat 
= 4
: nat
\end{coqout-right}


\section{Propositions, implication, universal quantification}\label{sec:propiuq}

The sort \C{Prop} is the type of propositions. If \C{A} and \C{B} are
two types in sort \C{Prop}, then \C{A -> B} is also a type, living as well in
sort \C{Prop}. A term of type \C{A -> B} is a function, that
transforms any term of type \C{A} into a term of type \C{B}, and that
can be applied to any term of type \C{A}. This is the central typing
rule of our formal system. It is a deep remark that the
typing rules governing the construction of a term with an arrow type,
and the application of such a term to another can be read as the
introduction rule and elimination rule of the implication,
respectively. For instance, let us analyse a proof that modus ponens holds:

\begin{coq}{}{}
Lemma modus_ponens (A B : Prop) : (A -> B) -> A -> B.
Proof.
move=> hAB hA.
apply: hAB.
exact: hA.
Qed.
\end{coq}

This proof starts by introducing the two hypotheses, 
akin to the two arguments of a function. Then it builds a proof of 
\C{B} which is the result of the function \C{hAB} applied to the argument \C{hA}.
A variant is:

\begin{coq}{}{}
Lemma modus_ponens (A B : Prop) : (A -> B) -> A -> B.
Proof.
move=> hAB hA.
exact: (hAB hA).
Qed.
\end{coq}

A last variant, providing directly the proof, without interactive commands:

\begin{coq}{}{}
Lemma modus_ponens (A B : Prop) : (A -> B) -> A -> B.
Proof.
exact: (fun hAB hA => hAB hA).
Qed.
\end{coq}

The remark extends to universal quantification, whose introduction and
elimination rules also coincide with the formation and application
rules of a product type. Just like the constructive proof of an
implication is a function transforming an arbitrary proof of the
premise into a proof of the conclusion, a constructive proof of a
universal statement is a family of proofs, indexed by the inhabitants
of the type over which quantification takes place. In this view, 
a proof of the Pythagorean theorem is a family of proofs indexed by
the collection of rectangular triangles.




%% Universal quantification is not only useful to form types that
%% play the role of propositions.  It can come handy to form data types
%% too.  In the second part of this book (section~\ref{sec:matrix})
%% we shall see how the matrix data type
%% and the type of its multiplication function benefit from it.

%% \begin{coq}{}{}
%% matrix : Type -> nat -> nat -> Type.
%% mulmx : forall R : Type, forall m n p : nat,
%%   matrix R m n -> matrix R n p -> matrix R m p.
%% \end{coq}

%% This time the data type of matrices exposes the size, and matrix multiplication
%% can be given a type that rules out incompatible matrices and also describes

%% the size of the resulting matrix in terms of the size of the input
%% ones.\footnote{To be precise, \C{mulmx} also needs to take in input operations to
%% add and multiply elements of \C{R}.  Such detail plays no role in the current
%% discussion.}

%% This is in fact a classic example of what is called a \emph{dependent type}: a
%% data type depending on data, two natural numbers here.
%% \index[concept]{dependent type}

%% Note that in this formalism, quantification can range on the proofs of
%% a given statement, just like it can range on numbers. In this way, a
%% statement may express
%% a property shared by the proofs of a given statement. Such capability
%% finds a rare, but
%% crucial use in \mcbMC{} that we discuss in chapter~\ref{ch:sigmabool}:
%% All the proofs of a given equality statement between two booleans are
%% indistinguishable.

%% \begin{coq}{name=hedberg}{}
%% Lemma bool_irrelevance (P Q : bool) : forall e1 e2 : P = Q, e1 = e2.
%% \end{coq}


The proofs-as-programs correspondence has a visible impact in the proofs
part of the \mcbMC{} library.  In particular, quantified lemmas, being programs,
can be instantiated by simply passing arguments to them.  Exactly as one can
pass \C{3} to \C{addn} and obtain \C{(addn 3)}, the function adding three, one
can ``pass'' \C{3} to the lemma \C{addnC} and obtain a proof of the statement
\C{(forall y, 3 + y = y + 3)}.  Remark that the argument passed to \C{addnC}
shows up in the type of the resulting term \C{(addnC 3)}:  The type of the
\C{addnC} program \emph{depends} on the value the program is applied
to.  Functions whose codomain type depend on the value of their input
have a type of the form $\forall x : A, B$, where $x$ can occur in
$B$. When $B$ does not depend on $x$ the same type is written
$A\rightarrow B$, avoiding the useless introduction of a name $x$.
The former is sometimes called the \emph{dependent function space}
($\forall$) and the latter, the standard function space ($\to$).
\index[concept]{dependent function space}

\mantra{Lemma names can be used as functions, and you can pass
arguments to them.
For example,
\C{(addnC 3)} is a proof that \C{(forall y, 3 + y = y + 3)}, and
\C{(prime_gt0 p_pr)} is a proof that \C{(0 < p)} whenever
\C{(p_pr : prime p)}.}

Yet providing all the arguments of a given lemma, so as to describe
the precise instance useful in a proof, can be tedious. It is one of
the duties of the language used in the interactive construction of
proofs to leverage this bureaucracy. For instance, the tactics
\C{apply} and \C{rewrite} introduced in Chapter~\ref{ch:proofs} are
designed to guess some of these arguments. This guess is based on
matching and unification with the current goal, or with a pattern
provided in argument.




We refer the reader
to the reference manual of \Coq{}~\cite{Coq:manual} for the other
rules of the system, which are variants of the ones we presented or
which express subtleties of the type system that are out of the scope of
the present book, like the difference between the sorts \C{Prop} and
\C{Type}.





\section{Conversion}\label{sec:conv}
The \emph{conversion (typing) rule} in Gallina describes the status of
computation in this dependent type theory, and plays a fundamental
role in the formalization choices adopted in the Mathematical
Component libraries. Computation is modeled by rewrite rules explaining how to
apply functions to their argument. For instance, the so-called
$\beta$-reduction rule rewrites an application of the form
\C{(fun x => t) u} into $t[u/x]$: the formal argument
$x$ is substituted by the actual argument $u$ in the body $t$ of the
function. A similar computation rule models the computation of a term of
the shape \C{(let x := u in t)} into $t[u/x]$. Two terms
$t_1$ and $t_2$ that are equal modulo computation rules are said to be
\emph{convertible}, written $t_1{}\equiv{}t_2$, and these terms
are indistinguishable to the type
\index[concept]{convertibility}
system. 
% We write  If $T_1$ and $T_2$ are two convertible types and if a term $t$
% has type $T_1$ in the context $\Gamma$, then $t$ also has type $T_2$
% in the context $\Gamma$:

% \begin{center}
% \AxiomC{\C{t : }$~T'$}
% \AxiomC{$T \equiv T'$}
% \RightLabel{conversion}
% \BinaryInfC{\C{t :}$~T$}
% \DisplayProof
% \end{center}


 This is the feature of the formalism that we
have used in section~\ref{ssec:proofcomp}: The proofs of the
statements \C{2 + 1 = 3} and \C{3 = 3} are the same, because the terms
\C{2 + 1 = 3} and \C{3 = 3} are convertible.  In chapter~\ref{ch:prog} and~\ref{ch:proofs}
we used boolean programs to express predicates and connectives exactly
to take advantage of convertibility: Also the compound
statement
\C{(2 != 7 && prime 7)} is convertible to \C{true}.
Finally, as illustrated in
section~\ref{sec:symcomp}, computation is not limited to terms without
variables: The term \C{(isT : true)}\footnote{In other words \C{isT} is a proof of all statements that are trivial by computation. We invite the reader that finds the writing \C{(isT : true)} ill typed to peek ahead to section~\ref{sec:coercions}.} is a valid proof of
\C{(0 < n.+1)}, as well as a proof of \C{(0 != p.+1)}.
\index[coq]{\C{isT}}

\marginpar{Say here that computation can be used for automation? and
  simpl? and that controlling it is a delicate issue?}


% One can also benefit from convertibility whenever one applies a lemma;
% otherwise said, whenever the $\to_E$ and $\forall_E$ rules apply.
% These rules check that the argument has
% the ``right type'', i.e. the type of
% the premise or of the  bound variable respectively.
% At the cost of being more verbose we could have made explicit
% in, say, the typing for $\to_E$
% that
% types are compared modulo computation as follows:
% \begin{center}
% \AxiomC{\C{f : }$~A \to B$}
% \AxiomC{\C{a : }$~A'$}
% \AxiomC{$A \equiv A'$}
% \RightLabel{$\to_E$}
% \TrinaryInfC{\C{(f a) :}$~B$}
% \DisplayProof
% \end{center}
% where $A \equiv A'$ denotes that $A$ and $A'$ are convertible.

\section{Inductive types}\label{ssec:indtypes}

Stricto sensu, in the formalism described in section~\ref{sec:terms},
types are either sorts, like \C{Prop} and \C{Type}, or functional
types constructed from these atomic ones. However, in the previous
chapters, we have casually used other types like \C{nat} or \C{bool}
and terms of these types like \C{O : nat} or \C{S : nat -> nat}.
In fact, in the Calculus of Inductive Construction it is also possible
to introduce new types -- and in fact new terms -- via
\emph{inductive definitions}~\cite{CoPa89, Moh93}. We only provide a
very brief overview of this subtle feature and again refer the reader
to the reference manual for a precise and formal account.

An inductive definition simultaneously introduces
several new objects into the context: a new type, in a given sort, and
new terms for the constructors, with their types. For instance, the
command:

\begin{coq}{}{}
Inductive nat : Type := O : nat | S (n : nat).
\end{coq}
introduces a new type \C{nat : Type} and two new terms \C{(O : nat)} and
\C{(S : nat -> nat)}. Constructors are functions, possibly of zero
arguments like \C{O}, and the codomain of a constructor of the
inductive type \C{T} is always \C{T}. An inductive type may occur as
the type of certain arguments of its constructors, like in the case of
\C{S}. The only way to construct an inhabitant of an
inductive type is to apply a constructor to sufficiently many
arguments:

\begin{coq}{name=nat-term-examples}{}
Unset Printing Notations.
Variable n : nat.

Check O.
Check S O.
Check S (S (S O)).
Check S (S (S n)).

\end{coq}

Note that for the sake of clarity, we do not make use in this section
of the posfix  notations \C{n.+1} for term \C{(S n)}, \C{n.+2} for
term \C{(S (S n))}, etc. so as to display constructors explicitely in examples.

Constructors are by definition injective functions: two terms
featuring the same head constructor can only be equal if the arguments
passed to this constructor are equal. E.g., in the following goal:

\begin{coqout}{name=nat-before-injection}{}
n, m : nat
eqSnSm : S n = S m
========================
G
\end{coqout}

where \C{G} is an arbitrary formula, it is possible to simplify
hypothesis \C{eqSnSm}:

\begin{coq-left}{name=nat-after-injection}{width=5cm}
case: eqSnSm.
$~$
$~$
$~$
$~$
\end{coq-left}
\begin{coqout-right}{}{width=7cm}
n, m : nat
========================
n = m -> G
\end{coqout-right}

Moreover, two distinct constructors construct distinct
terms; this is why a function with an argument of an inductive type can be
described by \emph{pattern matching} on this argument. For instance, in
chapter~\ref{ch:prog}, we have defined the non-zero test
function by:
\index[concept]{pattern matching}

\begin{coq}{name=predn}{}
Definition non_zero n := if n is (S p) then true else false.
\end{coq}
where we recall from Chapter~\ref{ch:prog} that \C{if ... then
  ... else ...} is a notation for the special case of pattern matching
with only two branches and one pattern. The definition of the terms of
the formalism is in fact extended with the \C{match ... with ... end}
construction described in section~\ref{ssec:nat}. A special reduction
rule expresses that pattern matching a term which features a certain
constructor in head position reduces to the term in the corresponding
branch of the case analysis.

The definition of the terms of CIC also includes so-called
\emph{guarded fixpoints}, which represent functions with a recursive
definition. We have used these fixpoints in chapter~\ref{ch:prog}, for
instance when defining the addition of two natural numbers as:

\begin{coq}{name=add_redef}{}
Fixpoint addn n m :=
  match n with
  | 0 => m
  | S p => S (addn p m)
  end.
\end{coq}
These fixpoints are said to be guarded because the corresponding
function should always terminate: more precisely, the \C{Fixpoint}
command expects termination to be visible from a syntactic
criterium. For instance, in the case of \C{addn}, the recursive call
happens on a strict subterm of the argument. Allowing
non-terminating computations for well-typed terms would actually
interact badly with the conversion rule, and ultimately lead to proofs
of absurdity (see section~\ref{ssec:indreason}). When the termination
argument of a function falls outside this syntactic guard condition,
its definition usually involves an extra argument, witnessing the
decreasing order relation. For a more detailed exposition of these
techniques, see for instance the corresponding chapter in Bertot and
Casteran's book~\cite{BC04}.




\section{More connectives}\label{sec:moreconns}
We have seen in section~\ref{sec:propiuq} that functions, i.e.~terms
with a product type, provide a datastructure for proofs of implication
and universally quantified statements.
Using inductive types, it is possible to describe more data
structures than mere functions. %of the formalism
% described in section~\ref{ssec:terms}. 
These data structures and their
typing rules are used to model every other logical connectives.

For instance, the introduction rule of the conjunction
connective
% \begin{center}
% \AxiomC{$A$} \AxiomC{$B$}
% \RightLabel{$\wedge_I$}
% \BinaryInfC{$A \wedge B$}
% \DisplayProof
% \hspace{1cm}
% \AxiomC{$A \wedge B$}
% \RightLabel{$\wedge_E$ (left)}
% \UnaryInfC{$A$}
% \DisplayProof
% \end{center}
reads: to prove $A \wedge B$ one needs to prove both
$A$ and $B$. Conversely, the elimination rule states that one proves 
$A$ whenever one is
able to prove the stronger statement $A \wedge B$.

In \Coq{} this connective is modeled by the following inductive
definition, which provides a type for pairs of proofs, of the
parameter statements \C{A} and \C{B}:

\begin{coq}{name=And}{}
Inductive and (A B : Prop) : Prop := conj (pa : A) (pb : B).
Notation "A /\ B" := (and A B).
\end{coq}
\index[vernac]{\C{Inductive}}

Remark that the ``data'' type \C{and} is tagged as \C{Prop}, i.e.,  we declare
the intention to use it as a logical connective rather than a data type.  The
single constructor \C{conj} takes two
arguments: a proof of \C{A} and a proof of \C{B}.
Moreover \C{and} is polymorphic:
\C{A} and \C{B} are parameters standing for arbitrary propositions.
As a consequence, it models faithfully the introduction rule of
conjunction, i.e. the rule govering the construction of proofs of
conjunctive statements.

Note that the definition of the pair data type,
in section~\ref{sec:othercontainers}, is almost identical to the one
of \C{and}:

\begin{coq}{}{}
Inductive prod (A B : Type) := pair (a : A) (b : B).
\end{coq}

Pattern matching provides the elimination rule for
conjunction, i.e. the (two) rules governing the construction of proofs
using a conjunctive hypothesis. Here is left elimination rule:

\begin{coq}{name=Ande1}{}
Definition proj1 A B (p : A /\ B) : A :=
  match p with conj a _ => a end.
\end{coq}
\index[coq]{\C{conj}}

Now recall the similarity between $\to$ and $\forall$, where the former is the
simple, non-dependent case of the latter.  If we ask for the type of
the \C{conj} constructor:

\begin{coq-left}{name=Ande1}{width=4cm}
About conj.
\end{coq-left}
\begin{coqout-right}{}{width=8cm}
conj: forall A B : Prop, A -> B -> A /\ B
\end{coqout-right}

we may wonder what happens if the type of the second argument (i.e., \C{B})
becomes dependent on the value of the first argument (of type \C{A}).
What we obtain is actually the inductive definition corresponding to the
existential quantification.

\begin{coq}{name=Ande1}{}
Inductive ex (A : Type) (P : A -> Prop) : Prop :=
  ex_intro (x : A) (p : P x).
Notation "'exists' x : A , p" := (ex A (fun x : A => p)).
\end{coq}
\index[coq]{\C{ex_intro}}

As  \C{ex\_intro} is the only constructor of the \C{ex} inductive
type, it is the only means to prove a statement like
\C{(exists n, prime n)}.  In such a --- constructive --- proof, the first
argument would be a number
\C{n} of type \C{nat} while the second argument would be a proof \C{p} of type
\C{(prime n)}.  The parameter \C{P} causes the dependency of the
second component of the pair on the first component. It is a function
representing an arbitrary predicate over a term of
type \C{A}.  Hence \C{(P x)} is the instance of the predicate, for \C{x}.  E.g.,
the predicate of being an odd prime number is expressed as
\C{(fun x : nat => (odd x) && (prime x))}, and the statement expressing the
existence of such a number is

\centerline{\C{(ex nat (fun x : nat => (odd x) && (prime x)))}} 
which (thanks to the \C{Notation} mechanism of \Coq{}) is parsed and
printed as the more familiar \C{(exists x : nat, odd x && prime x)}.

It is worth summing up the many features of type theory that
intervene in the type of \C{ex} and \C{ex\_intro}:

\begin{coq}{}{}
ex : forall A : Type, (A -> Prop) -> Prop.
ex_intro : forall A : Type, forall P : A -> Prop, forall a : A, P a -> ex A P.
\end{coq}

Both \C{ex} and \C{ex_intro} are parameterized by \C{(A : Type)}: as
we have seen in chapter~\ref{ch:prog}, the \C{(forall A : Type)}
quantification indicates that \C{ex} are \C{ex_intro} \C{polymorphic}
constants, that can be instantiated for any type. Both \C{ex} and
\C{ex_intro} also have a parameter of type  \C{(A -> Prop)}: since it
does not appear in the rest of the type of \C{ex}, this parameter is
not named and the type uses the arrow syntax instead of a more verbose
\C{forall A : Type, forall P : A -> Prop, Prop}. This parameter is
indicated by a so-called \emph{higher-order} quantification, because
the parameter has an arrow type. Constants  \C{ex} and \C{ex_intro}
can thus be  be specialized to any predicate \C{P}, so that the \C{ex}
inductive declaration can be used on any formula. Finally, the
\C{ex_intro} constant features a last, inner-most \C{forall a : A}
quantifier, which binds a term variable \C{a} representing the witness
of the existential statement for \C{P}.\\

Let us also observe the inductive definition of the disjunction \C{or}
and its two constructors \C{or\_introl} and \C{or\_intror}.

\begin{coq}{name=Or}{}
Inductive or (A B : Prop) : Prop := or_introl (a : A) | or_intror (b : B).
Notation "A \/ B" := (or A B).
\end{coq}

The elimination rule can again be expressed by pattern matching:

\begin{coq}{name=Or}{}
Definition or_ind (A B P : Prop)
  (aob : A \/ B) (pa : A -> P) (pb : B -> P) : P :=
  match aob with or_introl a => pa a | or_intror b => pb b end.
\end{coq}
\index[coq]{\C{or_introl}}
\index[coq]{\C{or_intror}}

The detail worth noting here is that the pattern match construct has two
branches, and each branch represents a distinct sub proof.  In this
case, in order to prove \C{P} starting from \C{A \\/ B},
one has to deal with all cases: i.e., to prove \C{P} under the
assumption \C{A}, and to prove \C{P}
under the assumption \C{B}.

Usual constants and connectives such as $\top$, $\bot$ and $\neg$
can be defined as follows.

\begin{coq}{name=TrueFalse}{}
Inductive True : Prop := I.
Inductive False : Prop := .
Definition not (A : Prop) := A -> False.
Notation "~ A" := (not A).
\end{coq}
\index[coq]{\C{True}}
\index[coq]{\C{False}}
\index[coq]{\C{I}}
\index[coq]{\C{not}}

Hence, in order to prove \C{True}, one just has to apply the
constructor \C{I}, which requires no arguments.
So proving \C{True} is trivial, and as a consequence eliminating it
provides little help (i.e., no extra knowledge is obtained by pattern matching
over \C{I}).  Contrarily, it is impossible to prove \C{False}, since it has no
constructor, and pattern matching on \C{False} can inhabit any type, since no
branch has to be provided:

\begin{coq}{name=exfalso}{}
Definition exfalso (P : Prop) (f : False) : P :=
  match f with end.  (* no constructors, no branches *)
\end{coq}

The only base predicate we still haven't described is equality.  The reason we
left it as the last one is that it has a tricky nature.  In particular,
equality, as we have seen in the previous chapters, is an open notion
in the following sense.  Terms that compute to the same syntactic expression
are considered as equal, and this is true for any program the user may write.
Hence such notion of equality needs to be somewhat primitive, as
\C{match} and \C{fun} are.  One also expects such notion to come
with a substitutivity property: replacing equals by equals must be licit.

The way this internal notion is exposed is via the concept of index
on which an inductive type may vary.

\begin{coq}{name=Eq}{}
Inductive eq (A:Type) (x:A) : A -> Prop := erefl : eq A x x.
Notation "x = y" := (@eq _ x y).
\end{coq}
\index[concept]{equality}
\index[coq]{\C{erefl}}

This is the first time we see a function type after the \C{:} symbol
in an inductive type declaration.
The \C{eq} type constructor takes three arguments: a type \C{A} and
two terms of that type (the former is named \C{x}).
Hence one can write \C{(a = b)} whenever \C{a} and \C{b}
have the same type.
The \C{erefl} constructor takes no arguments, as \C{I}, but its type
annotation says it can be used to inhabit only the type \C{(x = x)}.
Hence one is able to prove \C{(a = b)} only when \C{a} and \C{b} are
convertible
(i.e., indistinguishable from a logical standpoint).
Conversely, by eliminating a term
of type \C{(a = b)} one discovers that  \C{a} and \C{b} are
equal and \C{b} can be freely replaced by \C{a}.

\begin{coq}{name=EqInd}{}
Definition eq_ind A (P : A -> Prop) x (px : P x) y (e : x = y) : P y :=
  match e with erefl => px end.
\end{coq}

The notion of equality is one of the most intricate aspects of type
theory; an in-depth study of it is out of the scope of this book.  The interested reader
finds an extensive study of this subject in~\cite{hottbook}.  %% Later in this
%% chapter we define and use other inductive types to take advantage
%% of the ``automatic'' substitution of the implicit equations we see here:
%% While \C{px} has type \C{(P x)}, it is accepted as an
%% inhabitant of \C{(P y)} because inside the \C{match} the term \C{y}
%% is automatically replaced by \C{x}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Inductive reasoning}\label{ssec:indreason}

In chapter~\ref{ch:prog} we have seen how to build and use (call or destruct)
anonymous functions and data types.  All these
constructions have found counterparts in the Curry-Howard correspondence.
The only missing piece is recursive programs.  For example,
\C{addn} was written by recursion on its first argument, and is a
function taking as input two numbers and producing a third one.
We can write programs by recursion that take as input, among regular  data,
proofs and produce  other proofs as output.  Let's look at the
induction principle for natural numbers through the looking glasses of the
Curry-Howard isomorphism.

\begin{coq}{}{width=3.5cm}
About nat_ind.
\end{coq}
\begin{coqout}{}{width=9cm}
nat_ind : forall P : nat -> Prop,
  P 0 -> (forall n : nat, P n -> P n.+1) -> forall n : nat, P n
\end{coqout}
\C{nat\_ind} is a program that produces a proof of \C{(P n)} for any \C{n},
proviso a proof for the base case \C{(P 0)}, and a proof
of the inductive step \C{(forall n : nat, P n -> P n.+1)}.
Let us write such a program by hand.

\begin{coq}{}{}
Fixpoint nat_ind (P : nat -> Prop)
  (p0 : P 0) (pS : forall n : nat, P n -> P n.+1) n : P n :=
  if n is m.+1 then
    let pm (* : P m *) := nat_ind P p0 pS m in
    pS m pm (* : P m.+1 *)
  else p0.
\end{coq}
\index[coq]{\C{nat\_ind}}

The \Coq{} system generates this program automatically, as soon as
 the \C{nat} data type
is defined. 

It is worth mentioning that this principle is general enough to
prove the ``stronger'' induction principle that give access, in
the inductive step, to the property \C{P} on all numbers
small than \C{n.+1} and not just its predecessor.

\begin{coq}{}{}
Lemma strong_nat_ind (P : nat -> Prop)
  (base : P 0)
  (step : forall n, (forall m, m <= n -> P m) -> P n.+1) x : P x.
\end{coq}{}{}

In order to prove this statement it is sufficient to craft
the right ``P'' for \c{nat_ind}.

\begin{coq}{}{}
Check (nat_ind (fun n => forall m, m <= n -> P m)).
\end{coq}{}{}
\begin{coqout}{}{}
  (forall m, m <= 0 -> P m) ->
  (forall n, (forall m, m <= n -> P m) -> forall m, m <= n.+1 -> P m) ->
  forall n m, m <= n -> P m
\end{coqout}{}{}

If we fulfill the last premise with \C{(leqnn x : x <= x)} we obtain
the following proof goals:

\begin{coq}{}{}
Proof.
apply: (nat_ind (fun n => forall m, m <= n -> P m) _ _ x x (leqnn x)).
\end{coq}{}{}
\begin{coqout}{}{}
  P : nat -> Prop
  base : P 0
  step : forall n : nat, (forall m : nat, m <= n -> P m) -> P n.+1
  x : nat
  ============================
  forall m : nat, m <= 0 -> P m

subgoal 2 is:
 forall n : nat,
 (forall m : nat, m <= n -> P m) -> forall m : nat, m <= n.+1 -> P m
\end{coqout}{}{}

The two goals follow from \C{base} and \C{step} respectively.
Induction principles like this one can be used by giving their name to \C{elim} as in
\C{elim/strong_nat_ind}. Still, strong induction is such a frequent
proof step that the \mcbMC{} library provides dedicated idioms
that we will detail in Section~\ref{sec:ubnP}.

Finally, recall that recursive functions are checked for termination:
Through the lenses of the proofs-as-programs correspondence, this means
that the induction principle just coded is sound, i.e., based on a
well-founded order relation.
\index[concept]{termination}
\index[concept]{consistency}

If non-terminating functions are not ruled out, it is easy to inhabit
the \C{False} type, even if it lacks a proper constructor.

\begin{coq}{}{}
Fixpoint oops (n : nat) : False := oops n.
Check oops 3.  (* : False *)
\end{coq}
Of course \Coq{} rejects the definition of \C{oops}.  To avoid
losing consistency, \Coq{} also enforces some restrictions on
inductive data types.  For example the declaration of \C{hidden}
is rejected.

\begin{coq}{}{}
Inductive hidden := Hide (f : hidden -> False).
Definition oops (hf : hidden) : False := let: Hide f := hf in f hf.
Check oops (Hide oops).  (* : False *)
\end{coq}
Note how \C{oops} calls itself, as in the previous example,
even if it is not a recursive function.
Such restriction, called
\emph{positivity condition}, is out of scope for this book.
(Roughly speaking, it says that constructors for an inductive data
type can only depend on maps \emph{to} the data type but not on maps
\emph{from} it.)
The interested reader shall refer to~\cite{Coq:manual}.
\index[concept]{positivity}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \section{On the status of Axioms}
%% \label{sec:EM}

%% Not all valid reasoning principles can be represented by programs.
%% For example, excluded middle --- i.e., the claim that
%% \C{A \\/ ~~ A} for a given logical statement \C{A} ---
%% can be proved by a program only when
%% \C{A} is decidable, i.e., when we can write in \Coq{} a program
%% to \C{bool} that tests if \C{A} holds or not.
%% Excluded middle, in its generality, can only be \emph{axiomatized},
%% i.e., assumed globally.

%% The \mcbMC{} library is axiom free.  This makes the library compatible
%% with any combination of axioms that is known to be consistent with the
%% Calculus of Inductive Constructions. Some formal developments in
%% \Coq{} tend to assume the excluded middle axiom, even if the proofs
%% formalized do not require it, to avoid (or postpone) proving the
%% decidability of the predicates at play while still being able to
%% reason by case analysis on their validity. By contrast, the \mcbMC{}
%% library provides the decidability proofs when they exist. Moreover, the
%% boolean reflection methodology, object of chapter~\ref{ch:boolrefl},
%% provides tools to manipulate decidable predicates in a convenient way,
%% with the same ease as in a formalism based on a classical logic.

%% Yet sometimes it is not possible to provide a constructive proof of a
%% statement. In this case, axioms like the excluded middle axiom can
%% still be confined into ``boxes''. The purpose of these boxes is to
%% delimit a local context in which the required axioms are
%% available. Such a box is typically called a \emph{monad}
%% in the theory of programming languages. Here is an example, for the
%% axiom of excluded middle:

%% \begin{coq}{}{}
%% Definition classically P : Prop := forall b : bool, (P -> b) -> b.
%% Lemma classic_EM P : classically (decidable P).
%% Lemma classicW P : P -> classically P.
%% Lemma classic_bind P Q :
%%   (P -> classically Q) -> classically P -> classically Q.
%% \end{coq}
%% \index[coq]{\C{classically}}
%% \index[coq]{\C{classically_EM}}
%% \index[coq]{\C{classicW}}
%% \index[coq]{\C{classically_bind}}
%% % [DG] If we mention monads, let's include their unit.
%% %assia : TODO
%% The \C{classically} box can only be opened when the statement to be
%% proved in the current goal is a boolean, hence an instance of a
%% decidable predicate. Inside such a box the excluded middle is
%% made available by combining \C{classic_EM} and \C{classic_bind}.
%% Nevertheless, when proving a statement that is not a boolean, like
%% \C{exists n, ...}, one cannot access assumptions in the \C{classically} box.

%% In other cases, axioms can be avoided by rephrasing the mathematics
%% in a weaker setting.  A notable example in the \mcbMC{} library
%% is the construction of the real closure of an Archimedean
%% field~\cite{DBLP:conf/itp/Cohen12}.
%\marginnote{TODO Cyril: say more about RCF}
